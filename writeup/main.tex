\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{macro_math}

\usepackage{natbib}
\usepackage{graphicx}
\usepackage{fullpage}

\begin{document}

\title{Improved Analysis of Multi-Task Learning using Random Matrix Theory}
%\author{Hongyang Zhang}
\maketitle
\author \date{{\ddmmyyyydate\today} at \currenttime}
\usepackage[us,12hr]{datetime}
\date{}



\section{Problem setup}

\begin{enumerate}
%    \item {\bf The distributed learning problem.}
%    \begin{align}
 %     f(w) = \sum_{i=1}^k \normFro{X_i w - Y_i}^2. \label{eq_dist}
 %   \end{align}
 %   A natural setting is when the covariance matrices $X_i^{\top} X_i$ are different, i.e. having different spetrum.
 %   This is also known as covariate shift in the literature.
 %   Our hypothesis is that the covariate shift can slow down the convergence of learning the true $\theta$ as a function of the number of data opints.
  \item {\bf The multi-task learning problem.} \\
    {\it Different covariates:}
    If we follow the model setup of the first problem, but consider the following objective instead.
    \begin{align}
        f(B; A_1, \dots, A_k) = \sum_{i=1}^k \normFro{X_i B A_i - Y_i}^2.
    \end{align}
    This is a slightly more complicated parameterization of the first problem, in that each $A_i$ can select a model from the subspace of $B$ to fit $(X_i, Y_i)$.

    {\it Different models:} The most general version is when the covariates are different between different tasks and the single-task models are also different.
    Here the hypothesis is that the optimal $B$ is captured by a low-rank approximation of the single-task models.
\end{enumerate}

\section{General hypothesis}

Our hypothesis is that the heterogeneity among the multiple tasks can be categorized into two classes, \textit{covariate shift} and \textit{model shift}. \todo{Add some references to add spice on these takes.}

\subsection{Covariate shift}

In this setting, we assume that the covariates of task $i$ are drawn from $\Sigma_i \in \real^{d \times d}$, but the models are the same across all the tasks, i.e.
\begin{align}
  y_i = X_i \theta + \varepsilon_i, \mbox{ with } \frac 1 {n_i} X_i^{\top}X_i \sim \Sigma_i
\end{align}

Since the models are same, the most natural objective is using Equation \eqref{eq_dist}.

\begin{proposition}
  Show that adding tasks always helps or reduces estimation error.
\end{proposition}

\paragraph{The case of two tasks: $k = 2$.} We would like to get insight on how the covariate shift results in slower rates of transfer. The key quantity is to look at:
\begin{align}
  \tr[(X_1^{\top}X_1 + X_2^{\top} X_2)^{-1}]
\end{align}

\subsection{Model shift}

We remove the assumption that the models are the same. The $i$-th task data can be viewed as generated by a separate model $\theta_i$. 
\begin{align}
  y_i = X_i \theta_i + \varepsilon_i.
\end{align}

%Several relevant directions on this setting.
%\begin{itemize}
%  \item {\bf Low-rank space of $\set{\theta_i}_{i=1}^k$.} We may assume that the task models themselves form a low-rank space. This imposes that the tasks should be related to each other in some way.
%  \item {\bf PCA-based averaging for distributed regression.} This also leads to a natural heuristic for the distributed learning problem.
%    After receiving $\hat{\theta_i}$, for $i = 1, 2,\dots, k$, we can apply PCA to find a low-rank space of the estimates.
%  \item {\bf The hypothesis testing view.} A practical question that often arises in MTL is, if we can access a new task data (say $k+1$-th), should we add the task to the existing set of tasks or not?
%    One hypothesis is to find the projecion of $\hat{\theta}_{k+1}$ to the low-rank space of the estimates.
%  \item {\bf MTL and matrix factorization.} Could we use the results from MF to solve MTL? Does the landscape of MTL connect to MF?
%\end{itemize}
\end{document}
