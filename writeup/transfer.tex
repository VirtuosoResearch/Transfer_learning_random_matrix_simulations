\section{Comparing Multi-Task Learning to Single-Task Learning}\label{sec_insight}

%We provide precise explanations to the phenomena of negative transfer in multi-task learning.
We provide tight bounds on the bias and variance of the multi-task estimator for two tasks.
We show theoretical implications for understanding the performance of multi-task learning.
(a) \textit{Task similarity}: we explain the phenomenon of negative transfer precisely as task models become different.
(b) \textit{Sample size}: we further explain a curious phenomenon where increasing the source sample size helps initially, but hurts eventually.
(c) \textit{Covariate shift}: as the source sample size increases, we show that the covariate shift worsens the performance of the multi-task estimator.
Finally, we extend our results from two tasks to many tasks with the same features.
%We explain from three perspectives, including \textit{task similarity}, \textit{sample size} and \textit{covariate shift}.
%We show how negative transfer occurs by varying task similarity or sample size.
%Then we show that when source task sample size becomes large, covariate shift causes more negative effects.

\subsection{Analyzing the Bias-Variance Tradeoff using Random Matrix Theory}\label{sec_main}

A well-known result in the high-dimensional linear regression setting states that $\tr[(X_2^{\top}X_2)^{-1}\Sigma_2]$ is concentrated around $1 / (\rho_2 - 1)$ (e.g. Chapter 6 of \cite{S07}), which scales with the sample size of the target task.
Our main technical contribution is to extend this result to two tasks.
We show how the variance of the multi-task estimator scales with sample size and covariate shift in the following result.
\begin{lemma}[Variance bound]\label{lem_cov_shift_informal}
	In the setting of two tasks,
	let $n_1 = \rho_1 \cdot p$ and $n_2 = \rho_2 \cdot$ be the sample size of the two tasks.
	Let $\lambda_1, \dots, \lambda_p$ be the singular values of the covariate shift matrix $\Sigma_1^{1/2}\Sigma_2^{-1/2}$ in decreasing order.
	%let $n_1 = \rho_1 \cdot p$ and $n_2 = \rho_2 \cdot p$ denote the sample sizes of each task.
	%Let $\Sigma_1$ and $\Sigma_2$ denote the covariance matrix of each task.
	With high probability, the variance of the multi-task estimator $\hat{\beta}_t^{\MTL}$ equals
	%let $M = \Sigma_1^{1/2}\Sigma_2^{-1/2}$ and $\lambda_1, \lambda_2, \dots, \lambda_p$ be the singular values of $M^{\top}M$ in descending order.
%	For any constant $\e>0$, w.h.p. over the randomness of $X_1, X_2$, we have that
	{\small\begin{align*}%\label{eq_introX1X2}
		%\bigtr{(X_1^{\top}X_1 + X_2^{\top}X_2)^{-1}\Sigma_2} =
		\frac{\sigma^2}{n_1+n_2}\cdot \bigtr{ (\hat{v}^2 a_1 \Sigma_2^{-1/2}\Sigma_1\Sigma_2^{-1/2} + a_2\id)^{-1}} +\bigo{{p^{-1/2+o(1)}}},
	\end{align*}}%
	where $a_1, a_2$ are solutions of the following equations:
	{\small\begin{align*}
		a_1 + a_2 = 1- \frac{1}{\rho_1 + \rho_2},\quad a_1 + \frac1{\rho_1 + \rho_2}\cdot \frac{1}{p}\sum_{i=1}^p \frac{\hat{v}\lambda_i^2 a_1}{\hat{v}\lambda_i^2 a_1 + a_2} = \frac{\rho_1}{\rho_1 + \rho_2}.
	\end{align*}}
%are both fixed values that roughly scales with the sample sizes $\rho_1, \rho_2$, and satisfy $a_1 + a_2 = 1 - (\rho_1 + \rho_2)^{-1}$ plus another deterministic equation.
\end{lemma}
Lemma \ref{lem_cov_shift_informal} allows us to get a tight bound on equation \eqref{eq_te_var}, that only depends on \textit{sample size}, \textit{covariate shift} and the scalar $\hat{v}$.
As a remark, the concentration error $\OO(p^{-1/2+o(1)})$ of our result is nearly optimal.
For the bias term of equation \eqref{eq_te_model_shift}, a similar result that scales with task model distance in addition to sample size and covariate shift holds (cf. Lemma \ref{lem_cov_derivative} in Appendix \ref{app_proof_main_thm}).
Combining the two lemmas, we provide a sharp analysis of the bias-variance tradeoff of the multi-task estimator.
For a matrix $X$, let $\lambda_{\min}(X)$ denote its smallest singular value and $\norm{X}$ denote its spectral norm.
%The formal statement is stated in Theorem \ref{thm_many_tasks} and its proof can be found in Appendix \ref{app_proof_many_tasks}.
%The technical crux of our approach is to derive the asymptotic limit of $\te(\hat{\beta}_t^{\MTL})$ in the high-dimensional setting, when $p$ approaches infinity.
%We derive a precise limit of $\bigtr{(X_1^{\top}X_1 + X_2^{\top}X_2)^{-1}\Sigma_2}$, which is a deterministic function that only depends on $\Sigma_1, \Sigma_2$ and $n_1/p, n_2/p$ (see Lemma \ref{lem_cov_shift} in Appendix \ref{app_proof_main} for the result).
%Based on the result, we show how to determine positive versus negative transfer as follows.
%, where $\lambda_{\min}(M)$ is the smallest singular value of $M_1$
\begin{theorem}[Two tasks]\label{thm_main_informal}
	For the setting of two tasks, let $\delta > 0$ be a fixed error margin, $\rho_2 > 1$ and $\rho_1 \gtrsim \delta^{-2}\cdot \lambda_{\min}(\Sigma_1^{1/2}\Sigma_2^{-1/2})^{-4} \norm{\Sigma_1} \max(\norm{\beta_1}^2, \norm{\beta_2}^2)$, and .
 	There exists two deterministic functions $\Delta_{\bias}$ and $\Delta_{\vari}$ that only depend on $\set{\hat{v}, \Sigma_1, \Sigma_2, \rho_1, \rho_2, \beta_1, \beta_2}$ such that
	\squishlist
		\item If $\Delta_{\bias} - \Delta_{\vari} < -\delta$, then w.h.p. over the randomness of $X_1, X_2$, we have $\te(\hat{\beta}_t^{\MTL}) < \te(\hat{\beta}_t^{\STL})$.
		\item If $\Delta_{\bias} - \Delta_{\vari} > \delta$, then w.h.p. over the randomness of $X_1, X_2$, we have $\te(\hat{\beta}_t^{\MTL}) > \te(\hat{\beta}_t^{\STL})$.
	\squishend
\end{theorem}

Theorem \ref{thm_main_informal} applies to settings where large amounts of source task data is available but the target sample size is small.
For such settings, we obtain a sharp transition from positive transfer to negative transfer determined by $\Delta_{\bias} - \Delta_{\vari}$.
%determined by the covariate shift matrix and the model shift.
%The bounds get tighter and tighter as $\rho_1$ increases.
While the general form of these functions can be complex (as are previous generalization bounds for MTL), they admit interpretable forms for simplified settings.

%\textbf{Proof overview.}\todo{}
%Theorem \ref{lem_cov_shift_informal} extends a well-known result for the single-task setting when $X_1, \rho_1, a_1$ are all equal to zero \cite{S07}.
%Applying Theorem \ref{lem_cov_shift_informal} to \eqref{eq_te_var}, we can calculate the amount of reduced variance compared to STL, which is given asymptotically by $\Delta_{\vari}$.
%For the bias term in equation \eqref{eq_te_model_shift}, we apply the approximate isometry property to $X_1^{\top}X_1$, which is close to $n_1^2\Sigma_1$. This results in the error term $\delta$, which scales as $(1 + 1/\sqrt{\rho_1})^4-1$.
%Then, we apply a similar identity to Theorem \ref{lem_cov_shift_informal} for bounding the bias term, noting that the derivative of $R(z)$ with respect to $z$ can be approximated by $R_\infty'(z)$.
%This estimates the negative effect given by $\Delta_{\bias}$. %, which will be used to estimate the first term on the right hand side of \eqref{eq_te_model_shift}.
%During this process, we will get the $\Delta_{\bias}$ term up to an error $\delta$ depending on $\rho_1$.
The proof of Theorem \ref{thm_main_informal} is presented in Appendix \ref{app_proof_main_thm} and the proof of Lemma \ref{lem_cov_shift_informal} is in Appendix \ref{sec_maintools}.




\subsection{Task Similarity}\label{sec_similarity}

It is well-known since the seminal work of Caruana \cite{C97} that how well multi-task learning performs depends on task relatedness.
We formalize this connection in the following simplified setting, where we can perform explicit calculations.
We show that as we increase the distance between $\beta_1$ and $\beta_2$, there is a transition from positive transfer to negative transfer in MTL.

\textit{The isotropic model.}
	Consider two tasks with isotropic covariances $\Sigma_1 = \Sigma_2 = \id$.
	Each task has sample size $n_1 = \rho_1 \cdot p$ and $n_2 \rho_2 \cdot p$.
	%And $X_1\in\real^{n_1\times p}, X_2\in\real^{n_2\times p}$ denote the covariates of the two tasks, respectively.
	Assume that for the target task, $\beta_2$ has i.i.d. entries with mean zero and variance $\kappa^2$.
	For the source task, $\beta_1 $ equals $\beta_2$ plus i.i.d. entries with mean $0$ and variance $d^2$.
	The labels are $Y_i = X_i\beta_i + \varepsilon_i$, where $\e_i$ consists of i.i.d. entries with mean zero and variance $\sigma^2$.
	For our purpose, it is enough to think of the order of $d$ being $1/\sqrt{p}$ and $pd^2/\sigma^2$ being constant.
%	We assume that all the random variables have subexponential decay, while keeping in mind that our results can be applied under weaker moments assumptions as shown in Appendix \ref{sec_maintools}.

%In the isotropic model, we show that as we increase the distance between $\beta_1$ and $\beta_2$ (or $d$), there is a transition from positive transfer to negative transfer in MTL.
%We measure model dissimilarity as $\norm{\beta_1 - \beta_2}^2$, which is the distance between source and target in the isotropic model.
%Figure \ref{fig_model_shift} provides a simulation when $p = 200$.
%{The rest of parameter settings can be found in Appendix \ref{app_synthetic}.}
%Our result below will provide an explanation to this phenomenon.
%Based on Theorem \ref{thm_model_shift}, we derive the transition threshold in the following proposition.
We introduce the following notations.
{\small\begin{align*}
	\Psi(\beta_1, \beta_2) = {\ex{\bignorm{\beta_1 - \beta_2}^2}} / {\sigma^2},  \quad \Phi(\rho_1, \rho_2) = \frac{(\rho_1 + \rho_2 - 1)^2}{\rho_1 (\rho_1 + \rho_2) (\rho_2 - 1)}.
\end{align*}}

\begin{proposition}[Task model distance]\label{prop_dist_transition}
	In the isotropic model, suppose that $\rho_1$ and $\rho_2 > 1$.
	Then
	%Whether $\te(\hat{\beta}_t^{\MTL})$ is lower than $\te(\hat{\beta}_t^{\STL})$ is determined by the ratio between $\Psi(\beta_1, \beta_2)$ and $\Phi(\rho_1, \rho_2)$:
	\squishlist
		\item If $\Psi(\beta_1, \beta_2) < \frac{1}{\nu} \cdot  \Phi(\rho_1, \rho_2)$, then w.h.p. over the randomness of $X_1,X_2$, $\te(\hat{\beta}_t^{\MTL}) < \te(\hat{\beta}_t^{\STL})$.
		\item If $\Psi(\beta_1, \beta_2) > {\nu} \cdot  \Phi(\rho_1, \rho_2)$, then w.h.p. over the randomness of $X_1,X_2$, $\te(\hat{\beta}_t^{\MTL}) > \te(\hat{\beta}_t^{\STL})$.
	\squishend
	Here {\small$\nu = (1-\oo(1))\min((1 - 1/\sqrt{\rho_1})^{-4}, (1 + 1/\sqrt{\rho_1})^{4})$}.
	Concretely, if $\rho_1 > 40$, then $\nu\in (1,2)$.
\end{proposition}


Proposition \ref{prop_dist_transition} simplifies Theorem \ref{thm_main_informal} in the isotropic model, allowing for a more explicit statement of the bias-variance tradeoff.
Concretely, $\Psi(\beta_1, \beta)$ and $\Phi(\rho_1, \rho_2)$ corresponds to $\Delta_{\bias}$ and $\Delta_{\vari}$, respectively.
Roughly speaking, the transition threshold scales as $\frac{pd^2}{\sigma^2} - \frac{1}{\rho_1} - \frac{1}{\rho_2}$.
We apply Proposition \ref{prop_dist_transition} to the parameter setting of Figure \ref{fig_model_shift} (the details are left to Appendix \ref{app_synthetic}).
We can see that our result is able to predict positive or negative transfer  accurately that matches the empirical curve.
There are several unexplained observations near the transition threshold $0$, which are caused by the concentration error $\nu$.
%We fix the target task and vary the source task, in particular the parameter $d$ which determines $\norm{\beta_1 - \beta_2}$.
%Figure \ref{fig_model_shift} shows the result.
%We observe that Proposition \ref{prop_dist_transition} explains most of the observations in Figure \ref{fig_model_shift}.
%The proof of Proposition \ref{prop_dist_transition} involves two parts.
%First, in equation \eqref{eq_te_var}, the positive variance reduction effect scales with $n_1 = \rho_1 p$, the number of source task data points.
%Second, we show that the negative effect of model-shift bias scales with $pd^2$, which is the expectation of $\norm{\beta_1 - \beta_2}^2$.
The proof of Proposition \ref{prop_dist_transition} can be found in Appendix \ref{app_proof_31}.
A key part of the analysis shows that $\hat{v}\approx 1$ in the isotropic model,
thus simplifyling the result of Theorem \ref{thm_main_informal}.
%, which is based on our main result described later in Theorem \ref{thm_model_shift}.


\textbf{Algorithmic consequence.}
We can in fact extend the result to the cases where the noise variances are different.
In this case, we will see that MTL is particularly effective.
%As an extension of Proposition \ref{prop_dist_transition}, we observe that MTL is particular powerful when the labeled data of the source task is less noisy compared to the target task.
Concretely, suppose the noise variance $\sigma_1^2$ of task $1$ differs from the noise variance $\sigma_2^2$ of task $2$.
If $\sigma_1^2$ is too large, the source task provides a negative transfer to the target.
If $\sigma_1^2$ is small, the source task is more helpful.
We leave the result to Proposition \ref{prop_var_transition} in Appendix \ref{app_proof_31}.
Inspired by the observation, we propose a single-task based metric to help understand MTL results using STL results.
\squishlist
	\item For each task, we train a single-task model.
	Let $z_s$ and $z_t$ be the prediction accuracy of each task, respectively.
	Let $\tau\in(0, 1)$ be a fixed threshold.
	\item If $z_s - z_t > \tau$, then we predict that there will be positive transfer when combining the two tasks using MTL.
	If $z_s - z_t < -\tau$, then we predict negative transfer.
\squishend

\subsection{Sample Size}\label{sec_data_size}

In classical Rademacher or VC based theory of multi-task learning, the generalization bounds are usually presented for settings where the sample sizes are equal for all tasks \cite{B00,M06,MPR16}.
%More generally, such results are still applicable when all task data are being added simultaneously.
On the other hand, uneven sample sizes between different tasks (or even dominating tasks) have been empirically observed as a cause of negative transfer \cite{YKGLHF20}.
For such settings, we have also observed that adding more labeled data from one task does not always help.
%On the other hand, we have observed that adding more labeled data does not always improve performance in multi-task learning.
In the isotropic model, we consider what happens if we vary the source task sample size.
Our theory accurately predicts a curious phenomenon, where increasing the sample size of the source task results in negative transfer!
%Figure \ref{fig_size} provides a simulation result for such a setting.
%We observe that as $n_1 / n_2$ increases, there is a transition from positive to negative transfer.

\begin{proposition}[Source/target sample ratio]\label{prop_data_size}
	In the isotropic model, suppose that $\rho_1 > 40$ and $\rho_2 > 110$ are fixed constants, and $\Psi(\beta_1, \beta_2) > 2/(\rho_2 - 1)$.
	Then we have that
	\squishlist
		\item If $\frac{n_1}{n_2} = \frac{\rho_1}{\rho_2} < \frac{1}{\nu} \cdot \frac{1 - 2\rho_2^{-1}}{\Psi(\beta_1, \beta_2) (\rho_2 - 1) - \nu^{-1}}$, then w.h.p. $\te(\hat{\beta}_t^{\MTL}) < \te(\hat{\beta}_t^{\STL})$.
		\item If $\frac{n_1}{n_2} = \frac{\rho_1}{\rho_2} > {\nu} \cdot \frac{1 - 2\rho_2^{-1}}{\Psi(\beta_1, \beta_2) (\rho_2 - 1.5) - \nu}$, then w.h.p. $\te(\hat{\beta}_t^{\MTL}) > \te(\hat{\beta}_t^{\STL})$.
	\squishend
\end{proposition}
Proposition \ref{prop_data_size} describes the bias-variance tradeoff in terms of the sample ratio $n_1 / n_2$.
We apply the result to the parameter setting of Figure \ref{fig_size} (described in Appendix \ref{app_synthetic}).
There are several unexplained observations near $y = 0$ caused by $\nu$.
The proof of Proposition \ref{prop_data_size} can be found in Appendix \ref{app_proof_32}.

\textbf{Connection to Taskonomy.} We use our tools to explain a key result of Taskonomy by Zamir et al. (2018) \cite{ZSSGM18}, which shows that MTL can reduce the amount of labeled data needed to achieve comparable performance to STL.
%More precisely, suppose we have $n_i$ datapoints for each task, for $i= 1, 2$.
For $i = 1, 2$, let $\hat{\beta}_i^{\MTL}(x)$ denote the estimator trained using $x \cdot n_i$ datapoints from every task. The data efficiency ratio is defined as
{\small\[ \argmin_{x\in(0, 1)} ~~
		\te_1(\hat{\beta}_1^{\MTL}(x)) + \te_2(\hat{\beta}_2^{\MTL}(x))
		\le \te_1(\hat{\beta}_1^{\STL}) + \te_2(\hat{\beta}_2^{\STL}). \]}
For example, the data efficiency ratio is $1$ if there is negative transfer.
Using our tools, we show that in the isotropic model, the data efficiency ratio is
roughly
{\small\[ \frac{1}{\rho_1 + \rho_2} {+ \frac{2}{(\rho_1 +\rho_2)(\rho_1^{-1} + \rho_2^{-1} - \Theta(\Psi(\beta_1, \beta_2)))}}. \]}%
Compared with Proposition \ref{prop_dist_transition}, we see that when $\Psi(\beta_1, \beta_2)$ is smaller than $\rho_1^{-1} + \rho_2^{-1}$ (up to a constant multiple), the transfer is positive.
Moreover, the data efficiency ratio quantifies how effective the positive transfer is using MTL.
%In addition to $\rho_1,\rho_2$, the data efficiency ratio also scales with $\Psi(\beta_1, \beta_2)$, the model distance between the tasks.
The result can be found in Proposition \ref{prop_data_efficiency} in Appendix \ref{app_proof_32}.

\textbf{Algorithmic consequence.} An interesting consequence of Proposition \ref{prop_data_size} is that $L(\hat{\beta}_t^{\MTL})$ is not monotone in $\rho_1$.
In particular, Figure \ref{fig_size} (and our analysis) shows that $L(\hat{\beta}_t^{\MTL})$ behaves as a quadratic function over $\rho_1$.
More generally, depending on how large $\Psi(\beta_1, \beta_2)$ is, $L(\hat{\beta}_t^{\MTL})$ may also be monotonically increasing or decreasing.
Based on this insight, we propose an incremental optimization schedule to improve MTL training efficiency.
\squishlist
	\item We divide the source task data into $S$ batches.
	For $S$ rounds, we incrementally add the source task data by adding one batch at a time.
	\item After training $T$ epochs, if the validation accuracy becomes worse than the previous round's result, we terminate.
	Algorithm \ref{alg_inc_train} in Appendix \ref{app_experiments} describes the procedure in detail.
\squishend


\subsection{Covariate Shift}\label{sec_covshift}

So far we have considered the isotropic model where $\Sigma_1 = \Sigma_2$.
This setting is relevant for settings where different tasks share the same input features such as multi-class image classification.
In general, the covariance matrices of the two tasks may be different such as in text classification.
In this part, we consider what happens when $\Sigma_1 \neq \Sigma_2$.
We show that when $n_1 / n_2$ is large, MTL with covariate shift can be suboptimal compared to MTL without covariate shift.

\textit{Example.}
	We measure covariate shift by $M = \Sigma_1^{1/2} \Sigma_2^{-1/2}$.
	Assume that $\Psi(\beta_1, \beta_2) = 0$ for simplicity.
	We compare two cases: (i) when $M = \id$; (ii) when $M$ has $p/2$ singular values that are equal to $\lambda$ and $p/2$ singular values that are equal to $1 / \lambda$.
	Hence, $\lambda$ measures the severity of the covariate shift.
	Figure \ref{fig_covariate} shows a simulation of this setting by varying $\lambda$.
	We observe that as source/target sample ratio increases, the performance gap between the two cases increases.

%By applying Lemma \ref{lem_cov_shift_informal}, we find that when $n_1 / n_2$ is large, having no covariate shift is the optimal choice provided that the determinant of $M^{\top}M$ is bounded.
We compare different choices of $M$ that belong to the following bounded set.
Let $\lambda_i$ be the $i$-th singular value of $M$.
Let $\mu_{\min} < \mu < \mu_{\max}$ be fixed values that do not grow with $p$.
\vspace{-0.025in}
{\small\begin{align*}
		\cS_{\mu}\define\bigset{M \left| \prod_{i=1}^p \lambda_i \le \mu^p, \mu_{\min} \le \lambda_i\le \mu_{\max}, \text{ for all } 1\le i\le p\right.},
\end{align*}}
%	We assume that $\beta_1$ and $\beta_2$ are generated following the isotropic model with $d = 0$.
\begin{proposition}[Covariate shift]\label{prop_covariate}
	Assume that $\Psi(\beta_1, \beta_2) = 0$ and $\rho_1, \rho_2>1$.
	Let $g(M)$ denote the prediction loss of $\hat{\beta}_t^{\MTL}$ when $M = \Sigma_1^{1/2}\Sigma_2^{-1/2} \in\cS_{\mu}$.
	We have that
	{\small\[ g(\mu\id) \le \bigbrace{1+ \bigo{{\rho_2}/{\rho_1}  }} \min_{M\in\cS_{\mu}} g(M). \]}
\end{proposition}
This proposition shows that when source/target sample ratio is large, then having no covariate shift is optimal.
The proof of Proposition \ref{prop_covariate} is left to Appendix \ref{app_proof_33}.
%Proposition \ref{prop_covariate} implies that when $\rho_1\gg \rho_2$, having no covariate shift is the optimal choice for choosing the source task.
%This provides evidence that covariate shift is unfavorable when there are many source task datapoints,

%\todo{} To complement the result, we show an example when the statement is not true if $n_1 \le n_2$.

%We ask: is it better to have $M$ as being close to identity, or should $M$ involve varying levels of singular values?
%Understanding this question has implications for applying normalization methods in multi-task learning \cite{LV19,CBLR18,YKGLHF20}.
%We show that if $n_1$ is much larger than $n_2$, then the optimal $M$ matrix should be proportional to identity, under certain assumptions on its range of singular values (to be formulated in Proposition \ref{prop_covariate}).
%On the other hand, if $n_1$ is comparable or even smaller than $n_2$, we show an example where having ``complementary'' covariance matrices is better performing than having the same covariance matrices.


\textbf{Algorithmic consequence.}
Our observation highlights the need to correct covariate shift when $n_1 / n_2$ is large.
Hence for such settings, we expect procedures that aim at correcting covariate shift to provide more significant gains.
We consider a covariance alignment procedure proposed in Wu et al. (2020) \cite{WZR20}, which is designed for the purpose of correcting covariate shift.
The idea is to add an alignment module between the input and the shared module $B$.
This new module is then trained together with $B$ and the output layers.
We validate our insight on this procedure in the experiments.


\subsection{Extensions}

Next, we describe our result for more than two tasks with same features, i.e. $X_i = X$ for any $i$.
This setting is prevalent in applications of multi-task learning to image classification, where there are multiple prediction labels/tasks for every image \cite{chexnet17,EA20}.
\begin{theorem}[Many tasks]\label{thm_many_tasks}
%Suppose $X=Z\Sigma^{1/2}\in \R^{n\times p}$ satisfy Assumption \ref{assm_secA1} with $\rho:=n/p>1$ being some fixed constant. Consider data models  $Y_i = X\beta_i + \varepsilon_i$, $i=1,2,\cdots, t$, where $\e_i\in \R^{n}$ are random vectors with i.i.d. entries with mean zero, variance $\sigma^2$ and all moments as in \eqref{assmAhigh}. Moreover, assume that $X$, $\beta_i$ and $\e_i$ are all independent of each other.
	%Let $n = c \cdot p$.
	%Let $X\in\real^{n\times p}$ and $Y_i = X\beta_i + \varepsilon_i$, for $i = 1,\dots,k$.
%	Consider $t$ data models $Y_i = X\beta_i + \varepsilon_i$, $i=1,2,\cdots, t$, where $X$ has covariance matrix $\Sigma$, and the entries of $\e_i$ are i.i.d. with mean zero and variance $\sigma^2$.
	%that satisfy Assumption \ref{assm_secA2} in the appendix.
	For the setting of $t$ tasks where $X_i = X$, for all $1\le i\le t$.
	Let $B^\star := [{\beta}_1,{\beta}_2,\dots,{\beta}_{t}]$ and $U_r\in\real^{t\times r}$ denote the linear model parameters.
	Let $U_r U_r^{\top}$ denote the best rank-$r$ subspace approximation of $(B^{\star})^\top\Sigma B^{\star}$.
	Assume that $\lambda_{\min}({B^{\star}}^\top\Sigma B^{\star})\gtrsim \sigma^2$.
	Let $v_i$ denote the $i$-th row vector of $U_r$.
	There exists a value $\delta = \oo \left( \|B^\star\|^2 + \sigma^2\right)$ such that
	\squishlist
		\item  If	$\left(1 - \norm{v_t}^2 \right)\frac{\sigma^2}{\rho - 1} - \norm{\Sigma (B^{\star} U_r v_t - \beta_t)}^2 > \delta$, then w.h.p $\te(\hat{\beta}_t^{\MTL}) < \te(\hat{\beta}_t^{\STL})$.
		\item If $\left(1 - \norm{v_t}^2\right)\frac{\sigma^2}{\rho - 1} - \norm{\Sigma(B^{\star} U_r v_t - \beta_t)}^2 < -\delta$, then w.h.p. $\te(\hat{\beta}_t^{\MTL}) > \te(\hat{\beta}_t^{\STL})$.
	\squishend
\end{theorem}
Theorem \ref{thm_many_tasks} provides a sharp analysis of the bias-variance tradeoff beyond two tasks.
Specially, $(1 - \norm{v_t}^2)\sigma^2/(\rho - 1)$ shows the amount of reduced variance and $\norm{\Sigma (B^{\star} U_r v_t - \beta_t)}$ shows the bias of the multi-task estimator.
The proof of \ref{thm_many_tasks} can be found in Appendix \ref{app_proof_many_tasks}.

