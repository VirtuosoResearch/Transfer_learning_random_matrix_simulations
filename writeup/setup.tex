\section{Multi-Task vs. Single-Task Learning: The Bias-Variance Tradeoff}
\label{sec_main}

We first describe the bias-variance tradeoff in our setting more formally.
Then, we develop a key lemma that arises naturally in the high-dimensional setting.
Finally, we apply the lemma to provide a sharp analysis of the bias-variance tradeoff of multi-task and transfer learning in our setting.

\subsection{Problem Setup}\label{sec_setup}

Recall that we have $t$ labeled training datasets, denoted by $(X_1, Y_1), (X_2, Y_2), \dots, (X_t, Y_t)$, where $X_i\in\real^{n_i\times p}$ and $Y_i\in\real^{n_i}$ for $1\le i\le t$.
%Following \cite{HMRT19,BLLT20}, we assume that for each task $i = 1,2,\dots,t$,  every feature vector is generated as $x = \Sigma_i^{1/2} z$, where $z\in\real^p$ is a random vector with i.i.d. entries of mean zero and unit variance and $\Sigma_i\in\real^{p\times p}$ is a positive semidefinite matrix.
Without loss of generality, let the $t$-th task denote the target task.
We consider the following linear multi-task learning architecture.
\begin{align}
	\label{eq_mtl}
	f(B; W_1, \dots, W_t) = \sum_{i=1}^t \norm{X_i B W_i - Y_i}^2,
\end{align}
where $B\in\real^{p\times r}$ and $W_i\in\real^r$.
Here $B$ provides a shared subspace for all tasks and $W_i$ fits $B$ suitably to each task.
Following \cite{WZR20}, we assume that $r < t$, because otherwise minimizing $f(\cdot)$ could result in $BW_i$ to be the single-task optimum.
Hence there is no positive or negative transfer.
We define $\hat{\beta}_t^{\MTL}$ by two steps:
(i) minimizing $f(\cdot)$ over $B$;
(ii) minimize $\set{W_i}_{i=1}^k$ over an independent sample of the training set, e.g. $O(p^{0.99})$ suffices.
For more details, we refer the reader to Appendix \ref{app_proof_sec3}.
For an estimator $\hat{\beta}\in\real^p$, we define the out-of-sample prediction loss as
	\begin{align*}
		\te_t(\hat{\beta}) = \exarg{x}{({x}^{\top}\hat{\beta} - {x}^{\top}\beta_t)^2}
		= \bignorm{\ex{\hat{\beta}} - \beta_t}^2 + \ex{\bignorm{\hat{\beta} - \ex{\hat{\beta}}}^2},
	\end{align*}
%= (\hat{\beta} - \beta_t)^{\top}\Sigma_t(\hat{\beta} - \beta_t) \\
which can be further decomposed as the bias-variance tradeoff.
The single-task estimator $\hat{\beta}_t^{\STL}$ is given by $(X_t^{\top}X_t)^{-1}X_t^{\top}Y_t$.
In order to relate the tradeoff to properties of the data, we need tight concentration bounds for the bias and variance.
For this purpose, we consider the high-dimensional regime where $n_i$ is a fixed constant $\rho_i > 1$ times $p$ for every $1\le i\le t$, and $p$ is large.
We focus on a setting where $\rho_t$ is small compared to $\set{\rho_i}_{i=1}^{t-1}$.
This setting captures the need for adding more labeled data to reduce the prediction loss of the target task.
A well-known result for this setting states that $\te_t(\hat{\beta}_t^{\STL}) = \sigma^2 \cdot \tr[(X_t^{\top}X_t)^{-1}\Sigma_t]$ is concentrated around $\frac {\sigma^2} {\rho_t - 1}$ (e.g. Chapter 6 of \cite{S07}), which scales with the data size and noise level of the target task.
However, this result only applies to a single task.
Therefore, our goal is to extend this result to multiple tasks.

\textbf{Notations.}
When there is no ambiguity, we drop the subscript $t$ from $\te_t(\hat{\beta}_t^{\MTL})$ to $\te(\hat{\beta}_t^{\MTL})$ for simplicity.
We refer to the first task as the source task when there are only two tasks.
%We call $M = \Sigma_1^{1/2}\Sigma_2^{-1/2}$ the covariate shift matrix.

\subsection{Analyzing the Tradeoff via Random Matrix Theory}

To illustrate our intuition, we begin by considering the setting of two tasks with general covariance matrices.
%Recall that $\hat{\beta}_t^{\MTL}$ is defined as $BW_t$ after solving equation \eqref{eq_mtl}.
We decompose the test error of $\hat{\beta}_{t}^{\MTL}$ on the target task into two parts as follows.
\begin{align}
	\te(\hat{\beta}_t^{\MTL}) =& ~ \hat{v}^2 \bignorm{\Sigma_2^{1/2} (\hat{v}^2 X_1^{\top}X_1 + X_2^{\top}X_2)^{-1}X_1^{\top}X_1 (\beta_1 - \hat{v}\beta_2)}^2 \label{eq_te_model_shift} \\
	&+ \sigma^2\cdot \bigtr{(\hat{v}^2 X_1^{\top}X_1 + X_2^{\top}X_2)^{-1}\Sigma_2}, \label{eq_te_var}
\end{align}
Here $\hat{v}\in\real$ denotes a fixed value that depends on the output layer weights.
The role of $\hat{v}$ is to scale the shared subspace $B$ to fit each task.
These are derived in Appendix \ref{app_proof_sec3}.

Equation \eqref{eq_te_model_shift} corresponds to the bias of $\hat{\beta}_t^{\MTL}$, which captures how similar $\beta_1$ and $\beta_2$ are.
Hence, the bias of $\hat{\beta}_t^{\MTL}$ introduces a negative effect from adding the source labels.
Equation \eqref{eq_te_var} corresponds to the variance of $\hat{\beta}_t^{\MTL}$, which is always smaller than the variance of $\hat{\beta}_t^{\STL}$.
%This part introduces a positive variance reduction effect from adding the source labels.
Hence, whether $\te(\hat{\beta}_t^{\MTL}) < \te(\hat{\beta}_t^{\STL})$ is determined precisely by the bias-variance tradeoff!
%(i) the negative effect from model shift bias.
%(ii) the positive effect from variance reduction;



%\subsection{A Key Lemma using Random Matrix Theory}\label{label_rmt}



\textbf{Multi-task learning.}
We apply Theorem \ref{lem_cov_shift_informal} to provide a sharp analysis of the bias-variance tradeoff for two settings:
(i) two tasks with general covariance matrices;
(ii) any number of tasks that have the same features, i.e. $X_i = X_j$ for any $i\neq j$.
The latter setting is prevalent in applications of multi-task learning to image classification, where there are multiple prediction labels/tasks for every image \cite{chexnet17,EA20}.
We state our result for two tasks as follows.
%The formal statement is stated in Theorem \ref{thm_many_tasks} and its proof can be found in Appendix \ref{app_proof_many_tasks}.
%The technical crux of our approach is to derive the asymptotic limit of $\te(\hat{\beta}_t^{\MTL})$ in the high-dimensional setting, when $p$ approaches infinity.
%We derive a precise limit of $\bigtr{(X_1^{\top}X_1 + X_2^{\top}X_2)^{-1}\Sigma_2}$, which is a deterministic function that only depends on $\Sigma_1, \Sigma_2$ and $n_1/p, n_2/p$ (see Lemma \ref{lem_cov_shift} in Appendix \ref{app_proof_main} for the result).
%Based on the result, we show how to determine positive versus negative transfer as follows.

\begin{theorem}[Informal statement of Theorem \ref{thm_model_shift}]\label{thm_main_informal}
	For the setting of two tasks, let $M=\Sigma_1^{1/2}\Sigma_2^{-1/2}$, $\delta > 0$ be a desired error margin and $\rho_1 \gtrsim \frac{1}{\delta^2}\cdot \lambda_{\min}(M)^{-4} \norm{\Sigma_1} \max(\norm{\beta_1}^2, \norm{\beta_2}^2)$, where $\lambda_{\min}(M)$ is the smallest singular value of $M_1$.
	There exists two deterministic functions $\Delta_{\bias}$ and $\Delta_{\vari}$ that only depend on $\set{\hat{v}, \Sigma_1, \Sigma_2, \rho_1, \rho_2, \beta_1, \beta_2}$ such that
	\squishlist
		\item If $\Delta_{\bias} - \Delta_{\vari} < -\delta$, then w.h.p. over the randomness of $X_1, X_2$, we have $\te(\hat{\beta}_t^{\MTL}) < \te(\hat{\beta}_t^{\STL})$.
		\item If $\Delta_{\bias} - \Delta_{\vari} > \delta$, then w.h.p. over the randomness of $X_1, X_2$, we have $\te(\hat{\beta}_t^{\MTL}) > \te(\hat{\beta}_t^{\STL})$.
	\squishend
\end{theorem}

Theorem \ref{thm_main_informal} shows that as the source task data size increases, we obtain a sharp transition from positive transfer to negative transfer determined by $\Delta_{\bias} - \Delta_{\vari}$.
%determined by the covariate shift matrix and the model shift.
%The bounds get tighter and tighter as $\rho_1$ increases.
While the general form of the threshold can be complex (as is preivous generalization bounds for MTL), they admit interpretable forms for simplified settings.
This will be the focus of Section \ref{sec_insight}.


\textbf{Proof Overview.}
The proof of Theorem \ref{thm_main_informal} is presented in Appendix \ref{app_proof_main}.
The result for more than two tasks is deferred to Appendix \ref{app_proof_many_tasks}.

\textbf{Transfer learning.}
We extend Theorem \ref{thm_main_informal} to transfer learning settings.
We study the transfer procedure used in Taskonomy by Zamir et al.'18 \cite{ZSSGM18}.
For the setting of high-dimensional linear regression, the transfer procedure is as follows.
%Specifically, the source task encoder consists of the representations learnt from one or more source tasks.
%The transfer function then tries to fit the target task data to the source task encoder.
\squishlist
	\item \textit{Learning source task representations}: we obtain $\hat{\beta}_i^{\STL}$ from each source task, for $1\le i \le t-1$.
		This forms a shared representation ${B} = [\hat{\beta}_1,\hat{\beta}_2,\dots,\hat{\beta}_{t-1}]$.
	\item \textit{Fine-tuning on the target task}: we learn the output layer $W_t\in\real^{t-1}$ similar to equation \eqref{eq_mtl}
		\begin{align}
			g(W_t) = \bignorm{X_t B W_t - Y_t}^2.
		\end{align}
\squishend
After solving $W_t$, we use $\hat{\beta}_t^{\TL} = B W_t$ as the transfer learning (TL) estimator for the target task.
Our result naturally applies to $\hat{\beta}_t^{\TL}$.
Interestingly, we show that the model shift bias is simply the projection of $\beta_t$ to the orthogonal subspace of $B^{\star} = [\beta_1,\dots,\beta_{t-1}]$, or $\norm{\Sigma_t^{1/2}(\id - B^{\star}({B^{\star}}^{\top}B^{\star})^{-1}{B^{\star}}^{\top})\beta_t}^2$ more precisely.
The formal statement is presented in Theorem \ref{prop_taskonomy} and its proof in Appendix \ref{app_proof_sec4}.



%In order to analyze the tradeoff, we develop the following technical tool, which provides a tight bound for equation \eqref{eq_te_var}.
%where $(a_1, a_2)$ is the solution to the following deterministic equations:
%	\begin{align*}
%		a_1 + a_2 = 1- \frac{1}{\rho_1 + \rho_2},\quad a_1 + \frac1{\rho_1 + \rho_2}\cdot \frac{1}{p}\sum_{i=1}^p \frac{\lambda_i^2 a_1}{\lambda_i^2 a_1 + a_2} = \frac{\rho_1}{\rho_1 + \rho_2}.
%	\end{align*}

\textbf{Remark.} When there is only the target task, $\rho_1$ equals zero.
Hence $a_2 = 1 - 1/ \rho_2, a_1 = 0$ and Lemma \ref{lem_cov_shift_informal} states that $\tr[(X_2^{\top}X_2)^{-1}\Sigma_2] = \sigma^2 / (\rho_2 - 1)$, which is a well-known result in random matrix theory \cite{S07}.
Hence our result provides a necessary tool to analyze MTL in high dimensions.

