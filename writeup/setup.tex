\section{Introduction}

Multi-task learning that is applied on heterogeneous data can often result in suboptimal models (or negative transfer in more technical terms).
In a previous work \cite{WZR20}, we identified three factors that help determine when multi-task learning works, and when it doesn't.
In this work, we zoom in to the task covariance part of \cite{WZR20} to further understand when multi-task learning works for heterogeneous data.
We study a high-dimensional linear regression setting where the target task data size is limited.
We formulate the heterogeneity between different task data under covariate and model shifts \cite{PY09,K18}.
By using random matrix theory, we can explain several phenomena that are not explained by the techniques of \cite{WZR20}.
<<<<<<< HEAD
These are achieved through tight generalization bounds established in the high-dimensional regression setting.
Our main results are described as follows.
=======
\todo{list those here}
These are achieved through tight generalization bounds established in the high-dimensional regression setting using random matrix theory.

First, we provide a complete and precise picture for when there is positive vs negative transfer in the setting of learning two tasks.
>>>>>>> 7a264e06eec0f65422a2492170521b934dd03ca5
\begin{enumerate}
	\item {\bf De-noising effect of information transfer.}
	We provide a precise analysis for performing multi-task learning over two tasks under covariate and model shifts.
	We show that multi-task learning helps improve performance over target tasks by \textit{reducing variance} through newly added source task data.
	On the other hand, the difference between task models causes a negative effect that we call the \textit{model shift bias}.
	We show upper and lower bounds on both the amount of variance reduced and the amount of model shift bias incurred, which become tighter and tighter as the number of source task data points increases.
	%{\bf Negative transfer from model shift:} To complement the above result, we establish a fundamental limit of multi-task learning compared to single-task learning in the presence of model shift.
	%The phenomenon of negative transfer persists despite changing the model capacity or reweighting the tasks. [\textbf{done}]
	\item {\bf Effects of covariate shift, model distance, and data ratio.}
	We apply our general theory to compare the performance of three different estimators for the target task: multi-task training, single-task training and transfer learning.
	\begin{enumerate}
		\item {\bf Multi-task training over single-task training.} With multi-task training, since the training objective balances the losses from both the source and target tasks, the trained model can have worse performance for the target task.
	In particular, if model shift is too large, we get negative transfer from multi-task training.
		\item {\bf Transfer learning over single-task training.} Next we show that if we we only optimize the multi-task model on the target task, then we always obtain improved performance over single-task training.
		We provide fine-grained understanding on the amount of improvement that depends on covariate shift and data ratio.
		\item {\bf Transfer learning over multi-task training.} Finally, we show that the transfer learning estimator always improves over mutli-task training.
		The amount of improvement becomes more significant as the model distance becomes larger.
	\end{enumerate}
	\item {\bf Extending to many tasks with the same covariates.} For the general setting with $k$ tasks, we study the case when all tasks share the same covariates.
This setting is prevalent in applications of multi-task learning to image classification, where there are multiple prediction labels/tasks for every image \cite{EA20}.
	Since there is no covariate shift and the data ratio is always equal to one, the main factor is model distance.
	We show that our results and insights from the above can be extended to this setting as well.
\end{enumerate}



\section{Problem Setup}\label{sec_setup}

\paragraph{Data generation.}
In the multi-task learning (MTL) problem, we are given the input of $k$ tasks $(X_1, Y_1)$, $(X_2, Y_2)$, $\dots$, $(X_k, Y_k)$.
We shall assume that each task data follows a linear model.
For every $1\le i\le k$, we assume that
\[ Y_i = X_i \beta_i + \varepsilon_i, \]
where $\beta_i\in\real^p$ is the model parameter for the $i$-th task.
Each row of $X_i\in\real^{n_i\times p}$ is assumed to be drawn i.i.d. from a fixed distribution with covariance matrix $\Sigma_i$.
We assume that for every row $x$ of $X_i$, we have
\[ \ex{xx^{\top}} = \Sigma_i. \]
We also write $x = \Sigma_i^{1/2} z_i$, where $z_i$ is a random vector with mean $0$ and variance $1$.


\paragraph{Generalization error.}
We will designate the $k$-th task as the target.
Our goal is to come up with an estimator $\hat{\beta}$ to provide accurate predictions for the target task, provided with the other auxiliary task data.
Concretely, we focus on the test error for the target task:
%\begin{itemize}
%	\item Estimation error for the target model $\beta_t$: we consider their distance
%		\[ \err(\hat{\beta}) \define \exarg{\varepsilon_i, \forall 1\le i\le k}{\bignorm{\hat{\beta} - \beta_t}^2}. \]
		\begin{align*}
			\te_k(\hat{\beta}) &\define \exarg{x \sim \Sigma_k}{\exarg{{\varepsilon_i, \forall 1\le i\le k}}{(x^{\top}\hat{\beta} - x^{\top}\beta_t)^2}} \\
			&= \exarg{\varepsilon_i, \forall 1\le i\le k}{(\hat{\beta} - \beta_t)^{\top}\Sigma_k(\hat{\beta} - \beta_t)}.
		\end{align*}
%\end{itemize}

\paragraph{The MTL problem.}
We use a shared body (module) $B\in\real^{p\times r}$ for all tasks and a separate head (module) $\set{W_i \in \real^{r}}_{i=1}^k$ for each task.
%    \paragraph{Different covariates:}
This corresponds to minimizing the following optimization objective.
\begin{align}
	\label{eq_mtl}
	f(B; W_1, \dots, W_k) = \sum_{i=1}^k \norm{X_i B W_i - Y_i}^2.
\end{align}
Note that we consider the natural parameterization without reweighting the tasks above.
The shared body $B$ plays an important role because it allows information transfer between different task data.
There are two ways to ensure the sharing of information between tasks.
\begin{itemize}
	\item Adding a regularization over $B$, e.g. \cite{LPTV09,LPVT11}.
	\item Controlling the capacity $r$ of $B$, e.g. \cite{KD12,WZR20}. Moreover, \cite{KD12} observed that controlling the capacity can outperform the implicit capacity control of adding regularization over $B$.
\end{itemize}

\paragraph{The case of two tasks.}
From \cite{WZR20}, we know that either we need to explicitly restrict the capacity $r$ of $B$ so that there is transfer between the two tasks.
Following \cite{WZR20}, for the rest of the paper, we shall consider the case when $r=1$ since there are only two tasks.
Here, equation \eqref{eq_mtl} simplifies to the following
\[ f(B; w_1, w_2) = \bignorm{X_1 B w_1 - Y_1}^2 + \bignorm{X_2 B w_2 - Y_2}^2, \]
where $B\in\real^p$ and $w_1, w_2$ are both real numbers.
To solve the above, suppose that $w_1, w_2$ are fixed, by local optimality, we solve $B$ as
\begin{align*}
	\hat{B}(w) &= (w_1^2 X_1^{\top}X_1 + w_2^2 X_2^{\top}X_2)^{-1} (w_1 X_1^{\top}Y_1 + w_2 X_2^{\top}Y_2) \\
	&= \frac{1}{w_2} (w^2 X_1^{\top}X_1 + X_2^{\top}X_2)^{-1} (w X_1^{\top}Y_1 + X_2^{\top}Y_2) \\
	&= \frac{1}{w_2}\bigbrace{\beta_t + (w^2 X_1^{\top}X_1 + X_2^{\top}X_2)^{-1}\bigbrace{X_1^{\top}X_1(w\beta_s - w^2\beta_t) + (w X_1^{\top}\varepsilon_1 + X_2^{\top}\varepsilon_2)}},
\end{align*}
where we denote $w = w_1 / w_2$.
As a remark, when $w = 1$, we recover the linear regression estimator.

\medskip
\noindent\textit{Jointly optimizing over both tasks.}
Using a validation set that is sub-sampled from the original training dataset, we get a validation loss as follows
\begin{align}
		&\val(\hat{B}; w_1, w_2) \nonumber\\
	=& n_1 \cdot \bigbrace{\bignorm{\Sigma_1^{1/2}(w^2 X_1^{\top}X_1 + X_2^{\top}X_2)^{-1}X_2^{\top}X_2(\beta_s - w\beta_t)}^2 + \sigma^2 \cdot \bigtr{(w^2 X_1^{\top}X_1 + X_2^{\top}X_2)^{-1}\Sigma_1}} \nonumber \\
	+& n_2 \cdot \bigbrace{w^2\bignorm{\Sigma_2^{1/2}(w^2 X_1^{\top}X_1 + X_2^{\top}X_2)^{-1}X_1^{\top}X_1(\beta_s - w\beta_t)}^2 + \sigma^2 \cdot \bigtr{(w^2 X_1^{\top}X_1 + X_2^{\top}X_2)^{-1}\Sigma_2}} \label{eq_val_mtl}
\end{align}
Minimizing the above loss is akin to performing multi-task training in practice.
Let $\hat{w}$ denote the minimizer of $\val(\hat{B}; w_1, w_2)$ over $w\in\real$.
We will denote $\hat{\beta}_t^{\MTL} = w_{2}\hat{B}(\hat{w})$.

\medskip
\noindent\textit{Optimizing over the target task.} The validation loss of using $w_2 \hat{B}(w)$ for the target task is
\begin{align}
	\val(w_2\hat{B}(w)) =&~ w^2 \bignorm{\Sigma_2^{1/2}(w^2 X_1^{\top}X_1 + X_2^{\top}X_2)^{-1} X_1^{\top}X_1 (\beta_s - w \beta_t)}^2 \nonumber \\
			&~ + \sigma^2 \cdot \bigtr{(w^2 X_1^{\top}X_1 + X_2^{\top}X_2)^{-1} \Sigma_2}. \label{eq_te_mtl}
\end{align}
In the above, the first is a bias term introduced by the model shift between the source and target tasks.
The second is a variance term, which decreases monotonically as we add more and more source task data.
Let $\hat{w}$ denote the minimizer of $te(w_2 \hat{B})$ over $w\in\real$.
Note that we can obtain the value of $\te(w_1\hat{B})$ through a validation set.
We will denote $\hat{\beta}_t^{\TL} = w_2 \hat{B}(\hat{w})$.

There are two reasons for studying this setting.
First, this is akin to performing transfer learning using the hard parameter sharing architecture.
Another way to obtain $\hat{\beta}_t^{\TL}$ is that once we minimize the multi-task validation loss, we further minimize the validation loss on the target dataset, which is also known as fine-tuning in practice.
%\todo{may also consider test error}
%Several relevant directions on this setting.
%\begin{itemize}
%  \item {\bf Low-rank space of $\set{\theta_i}_{i=1}^k$.} We may assume that the task models themselves form a low-rank space. This imposes that the tasks should be related to each other in some way.
%  \item {\bf PCA-based averaging for distributed regression.} This also leads to a natural heuristic for the distributed learning problem.
%    After receiving $\hat{\theta_i}$, for $i = 1, 2,\dots, k$, we can apply PCA to find a low-rank space of the estimates.
%  \item {\bf The hypothesis testing view.} A practical question that often arises in MTL is, if we can access a new task data (say $k+1$-th), should we add the task to the existing set of tasks or not?
%    One hypothesis is to find the projecion of $\hat{\theta}_{k+1}$ to the low-rank space of the estimates.
%  \item {\bf MTL and matrix factorization.} Could we use the results from MF to solve MTL? Does the landscape of MTL connect to MF?
%\end{itemize}


\subsection{Hypothesis on Heterogeneous Task Data}

Our hypothesis is that the heterogeneity among the multiple tasks can be categorized into two classes, \textit{covariate shift} and \textit{model shift}. %\todo{Add some references to add spice on these takes.}
We consider two natural questions within each category.
\begin{itemize}
	\item How does covariate shift affect the rate of information transfer?
	For example, is it better to have the same covariance matrix or not?
	\item Under model shift, when do we get positive vs. negative transfer?
	How does the type of transfer depend on the number of data points, the distance of the task models etc?
\end{itemize}


\paragraph{Model shift.}
In general the single-task models can also be different across different tasks.
We shall argue that in addition to the bias and variance terms of generalization error, model shift introduces a third term which is the bias caused by model shift.

%\todo{Here the hypothesis is that the optimal $B$ is captured by a low-rank approximation of the single-task models?}
%We remove the assumption that the models are the same.
%The $i$-th task data can be viewed as generated by a separate model $\beta_i\in\real^p$.
%\begin{align}
%	Y_i = X_i \beta_i + \varepsilon_i.
%\end{align}


\paragraph{Covariate shift.}
The covariance matrices $\Sigma_i$ may be be different across tasks, i.e. having different spectrum or singular vectors.
This is also known as covariate shift in the literature.
%\todo{Our hypothesis is that the covariate shift can slow down the convergence of learning the true $\theta$ as a function of the number of data points.}
%A special case of this setting is that the single-task models are the same across all the tasks, i.e. $\beta_i = \beta$, for all $1\le i\le k$.
%\begin{align}
%	Y_i = X_i \beta + \varepsilon_i. %, \mbox{ with } \frac 1 {n_i} X_i^{\top}X_i \sim
%\Sigma_i
%\end{align}

\paragraph{Problem statement.} Our goal is to study under model and covariate shifts, whether multi-task learning helps learn the target task better than single-task learning.
The baseline where we solve the target task with its own data is
\begin{align*}
	te(\hat{\beta}_t^{\STL}) = \sigma^2 \cdot \bigtr{(X_1^{\top}X_1 + X_2^{\top}X_2)^{-1}}, \text{ where } \hat{\beta}_t^{\STL} = (X_2^{\top}X_2)^{-1} X_2^{\top}Y_2.
\end{align*}
Clearly, whether $\hat{\beta}_t^{\MTL}$ outperforms $\hat{\beta}_t^{\STL}$ depends on the covariate matrices, the difference of the task models, and the number of per-task data points.
Our goal is provide conditions under which there is positive transfer ($\te(\hat{\beta}_t^{\MTL}) \le \hat{\beta}_t^{\STL}$) or negative transfer ($\te(\hat{\beta}_t^{\MTL}) \ge \hat{\beta}_t^{\STL}$).
As a warm up, we show that when $\beta_s = \beta_t$, then the transfer is always positive.
%Since all tasks share the same underlying model $\beta$, we use a simplified objective as follows.
%\begin{align}
%	\label{eq_mtl_basic}
%	f(w) = \sum_{i=1}^k \norm{X_i w - Y_i}^2.
%\end{align}
%{\bf The distributed learning problem.}
%    \begin{align}
%     f(w) = \sum_{i=1}^k \normFro{X_i w - Y_i}^2. \label{eq_dist}
%   \end{align}
%Equation \eqref{eq_mtl_basic} is simplified from equation \eqref{eq_mtl} by setting $A_i$ to be 1 for all tasks. %can select a model from the subspace of $B$ to fit $(X_i, Y_i)$.

\begin{proposition}\label{prop_monotone}
	Suppose that $n > p$.
  When there is no model shift, i.e. $\beta_s = \beta_t$, adding the source task data always reduces the estimation error and the test error for the target task, i.e.
	\begin{align}
%		\err(\hat{\beta}_{t}^{\MTL})  &\le \err(\hat{\beta}_t^{\STL}), \text{ and} \label{eq_mono_e}\\
		\te(\hat{\beta}_{t}^{\MTL}) &\le \te(\hat{\beta}_t^{\STL}). \label{eq_mono_te}
	\end{align}
\end{proposition}

\begin{proof}
%	Equation \eqref{eq_mono_e} is simply because
%		\[ \err(\hat{\beta}_{s,t}) = \bigtr{(X_1^{\top}X_1 + X_2^{\top}X_2)^{-1}} \le \bigtr{(X_1^{\top}X_1)^{-1}} = \err(\hat{\beta}_t). \]
%	Equation \eqref{eq_mono_te} follows because
	Recall that $\hat{\beta}_t^{\MTL} = \hat{w} \cdot \hat{B}$.
	By the optimality of $\hat{w}$, we have by setting $w = 1$ in equation \eqref{eq_te_mtl}
	\begin{align*}
		\te(\hat{\beta}_t^{\MTL}) &\le \sigma^2 \cdot \bigtr{(X_1^{\top}X_1 + X_2^{\top}X_2)^{-1}\Sigma_2} \\
		&= \sigma^2 \cdot \bigtr{\bigbrace{\Sigma_2^{-1/2}X_1^{\top}X_1\Sigma_2^{-1/2} + \Sigma_2^{-1/2}X_2^{\top}X_2\Sigma^{-1/2}}^{-1}} \\
		&\le \bigtr{\bigbrace{\Sigma_2^{-1/2}X_2^{\top}X_2\Sigma_2^{-1/2}}^{-1}}
			= \bigtr{(X_2^{\top}X_2)^{-1} \Sigma_2} = \te(\hat{\beta}_t^{\STL}),
	\end{align*}
	which concludes the proof.
\end{proof}

As a remark, we can derive a similar result for the estimation error as well. The details are omitted.


\subsection{The High-Dimensional Setting}

%\todo{setup motivation and notations}
We would like to get insight on how covariate and model shifts affect the rate of transfer.
We will consider the high-dimensional setting where for the target task, its number of data points is a small constant times $p$.
This setting captures a wide range of applications of multi-task learning where we would like to use auxiliary task data to help train tasks with limited labeled data.
Furthermore, this setting is particularly suited to our study since there is need for adding more data to help learn the target task.

\paragraph{The case of two tasks.}
We can get precise rates using random matrix theory.
For the sake of clarity, we call task 1 the source task and task 2 the target task,
i.e. $\beta_1 = \beta_s$ and $\beta_2 = \beta_t$.
We introduce the following notations for the high-dimensional setting
\[ c_{n_1} \define \frac{n_1}{p} \to c_1, \quad c_{n_2} \define \frac{n_2}p \to c_2, \quad \text{as } \ n_1, n_2\to \infty, \]
for some constants $c_1, c_2 \in (1,\infty)$.
A crucial quantity is what we call the \textit{covariate shift} matrix $M = \Sigma_1^{1/2}\Sigma_2^{-1/2}$.
Let $\lambda_1, \lambda_2, \dots, \lambda_p$ denote the singular values of $M$.
% \gamma_n:= \frac{p} {n_1 + n_2} \to \gamma,

\begin{lemma}\label{lem_minv}[\todo{ref?}]
	In the setting when $n_2 = c_2 p$ we have that as $p$ goes to infinity,
	\[ \bigtr{(X_2^{\top}X_2)^{-1}\Sigma_2} = \frac{p}{n_2 - p}. \]
	%{\color{blue} \[ \bigtr{(X_2^{\top}X_2)^{-1}\Sigma_2} = \frac{p}{n_2 - p} . \]}
	%\bigtr{\Sigma_2^{-1}}
\end{lemma}