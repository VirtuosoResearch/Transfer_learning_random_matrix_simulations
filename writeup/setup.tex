\section{Multi-Task vs. Single-Task Learning: The Bias-Variance Tradeoff}
\label{sec_main}

We begin by describing our problem setup more formally.
Then, we describe our main result for the bias-variance tradeoff of multi-task and transfer learning estimators in our setting.

\subsection{Problem Setup}\label{sec_setup}

Recall that we have $t$ labeled training datasets, denoted by $(X_1, Y_1), (X_2, Y_2), \dots, (X_t, Y_t)$, where $X_i\in\real^{n_i\times p}$ and $Y_i\in\real^{n_i}$ for $1\le i\le t$.
%Following \cite{HMRT19,BLLT20}, we assume that for each task $i = 1,2,\dots,t$,  every feature vector is generated as $x = \Sigma_i^{1/2} z$, where $z\in\real^p$ is a random vector with i.i.d. entries of mean zero and unit variance and $\Sigma_i\in\real^{p\times p}$ is a positive semidefinite matrix.
Without loss of generality, let the $t$-th task be the target task.
We consider the following linear multi-task learning architecture.
\begin{align}
	\label{eq_mtl}
	f(B; W_1, \dots, W_t) = \sum_{i=1}^t \norm{X_i B W_i - Y_i}^2,
\end{align}
where $B\in\real^{p\times r}$ and $W_i\in\real^r$.
Here $B$ provides a shared subspace for all tasks and $W_i$ fits $B$ suitably to each task.
Following \cite{WZR20}, we assume that $r < t$, because otherwise minimizing $f(\cdot)$ could result in $BW_i$ being the single-task optimum.
Then applying equation \eqref{eq_mtl} will give the same estimator as single-task learning.
We define $\hat{\beta}_t^{\MTL}$ by two steps:
(i) minimizing $f(\cdot)$ over $B$;
(ii) minimize $\set{W_i}_{i=1}^k$ over an independent sample of the training set, e.g. $\OO(p^{0.99})$ suffices.
For more details, we refer the reader to Appendix \ref{app_proof_sec3}. The single-task estimator $\hat{\beta}_t^{\STL}$ is given by $(X_t^{\top}X_t)^{-1}X_t^{\top}Y_t$. 
For an estimator $\hat{\beta}\in\real^p$, we define the out-of-sample prediction loss as
	\begin{align*}
		\te_t(\hat{\beta}) = \exarg{x}{({x}^{\top}\hat{\beta} - {x}^{\top}\beta_t)^2}
		= \bignorm{\ex{\hat{\beta}} - \beta_t}^2 + \ex{\bignorm{\hat{\beta} - \ex{\hat{\beta}}}^2},
	\end{align*}
%= (\hat{\beta} - \beta_t)^{\top}\Sigma_t(\hat{\beta} - \beta_t) \\
which can be further decomposed as the bias plus the variance of $\hat{\beta}$.
%In order to relate the btradeoff to properties of the data, we need tight concentration bounds for the bias and variance.
We consider the high-dimensional regime where $n_i$ is a fixed constant $\rho_i > 1$  multiple of $p$ for every $1\le i\le t$, and $p$ is sufficiently large.
We focus on a setting where $\rho_t$ is small compared to $\set{\rho_i}_{i=1}^{t-1}$.
This setting captures the need to add more labeled data to reduce the prediction loss of the target task.
A well-known result for this setting states that $\te_t(\hat{\beta}_t^{\STL}) = \sigma^2 \cdot \tr[(X_t^{\top}X_t)^{-1}\Sigma_t]$ is concentrated around $\frac {\sigma^2} {\rho_t - 1}$ (e.g. Chapter 6 of \cite{S07}), which scales with the data size and noise level of the target task.
However, this result only applies to a single task.
Therefore, our goal is to extend this result to multiple tasks.

\textbf{Notations.}
When there is no ambiguity, we drop the subscript $t$ from $\te_t(\hat{\beta}_t^{\MTL})$ and write $\te(\hat{\beta}_t^{\MTL})$ for simplicity.
We refer to the first task as the source task when there are only two tasks.
%We call $M = \Sigma_1^{1/2}\Sigma_2^{-1/2}$ the covariate shift matrix.
We say there is negative transfer if the prediction loss of $\hat{\beta}_t^{\MTL}$ is larger than that of $\hat{\beta}_t^{\STL}$, or positive transfer otherwise.
For a matrix $X$, let $\lambda_{\min}(X)$ denote its smallest singular value and $\norm{X}$ denote its spectral norm.

\subsection{Analyzing the Tradeoff via Random Matrix Theory}

To illustrate our intuition, we begin by considering the setting of two tasks with general covariance matrices.
%Recall that $\hat{\beta}_t^{\MTL}$ is defined as $BW_t$ after solving equation \eqref{eq_mtl}.
We decompose the test error of $\hat{\beta}_{t}^{\MTL}$ on the target task into two parts as follows.
\begin{align}
	\te(\hat{\beta}_t^{\MTL}) =& ~ \hat{v}^2 \bignorm{\Sigma_2^{1/2} (\hat{v}^2 X_1^{\top}X_1 + X_2^{\top}X_2)^{-1}X_1^{\top}X_1 (\beta_1 - \hat{v}\beta_2)}^2 \label{eq_te_model_shift} \\
	&+ \sigma^2\cdot \bigtr{(\hat{v}^2 X_1^{\top}X_1 + X_2^{\top}X_2)^{-1}\Sigma_2}, \label{eq_te_var}
\end{align}
Here $\hat{v}\in\real$ denotes a fixed value that depends on the output layer weights $W_1, W_2$.
The role of $\hat{v}$ is to scale the shared subspace $B$ to fit each task.
These are derived in Appendix \ref{app_proof_sec3}.

Equation \eqref{eq_te_model_shift} corresponds to the bias of $\hat{\beta}_t^{\MTL}$, which captures how similar $\beta_1$ and $\beta_2$ are.
Hence, the bias of $\hat{\beta}_t^{\MTL}$ introduces a negative effect from adding the source labels.
Equation \eqref{eq_te_var} corresponds to the variance of $\hat{\beta}_t^{\MTL}$, which is always smaller than the variance of $\hat{\beta}_t^{\STL}$.
%This part introduces a positive variance reduction effect from adding the source labels.
Hence, whether $\te(\hat{\beta}_t^{\MTL}) < \te(\hat{\beta}_t^{\STL})$ is determined precisely by the tradeoff between the negative effect of the bias term and the positive effect of the variance term!
%(i) the negative effect from model shift bias.
%(ii) the positive effect from variance reduction;



%\subsection{A Key Lemma using Random Matrix Theory}\label{label_rmt}



%\textbf{Multi-task learning.}
We provide a sharp analysis of the bias-variance tradeoff two tasks with general covariance matrices.
We state our result for two tasks as follows.
%The formal statement is stated in Theorem \ref{thm_many_tasks} and its proof can be found in Appendix \ref{app_proof_many_tasks}.
%The technical crux of our approach is to derive the asymptotic limit of $\te(\hat{\beta}_t^{\MTL})$ in the high-dimensional setting, when $p$ approaches infinity.
%We derive a precise limit of $\bigtr{(X_1^{\top}X_1 + X_2^{\top}X_2)^{-1}\Sigma_2}$, which is a deterministic function that only depends on $\Sigma_1, \Sigma_2$ and $n_1/p, n_2/p$ (see Lemma \ref{lem_cov_shift} in Appendix \ref{app_proof_main} for the result).
%Based on the result, we show how to determine positive versus negative transfer as follows.
%, where $\lambda_{\min}(M)$ is the smallest singular value of $M_1$
\begin{corollary}\label{thm_main_informal}
	For the setting of two tasks, let $M=\Sigma_1^{1/2}\Sigma_2^{-1/2}$, $\delta > 0$ be a desired error margin and $\rho_1 \gtrsim \frac{1}{\delta^2}\cdot \lambda_{\min}(M)^{-4} \norm{\Sigma_1} \max(\norm{\beta_1}^2, \norm{\beta_2}^2)$.
	Let $\rho_2 > 1$ be a fixed value.
 	There exists two deterministic functions $\Delta_{\bias}$ and $\Delta_{\vari}$ that only depend on $\set{\hat{v}, \Sigma_1, \Sigma_2, \rho_1, \rho_2, \beta_1, \beta_2}$ such that
	\squishlist
		\item If $\Delta_{\bias} - \Delta_{\vari} < -\delta$, then w.h.p. over the randomness of $X_1, X_2$, we have $\te(\hat{\beta}_t^{\MTL}) < \te(\hat{\beta}_t^{\STL})$.
		\item If $\Delta_{\bias} - \Delta_{\vari} > \delta$, then w.h.p. over the randomness of $X_1, X_2$, we have $\te(\hat{\beta}_t^{\MTL}) > \te(\hat{\beta}_t^{\STL})$.
	\squishend
\end{corollary}

Corollary \ref{thm_main_informal} applies to settings where large amounts of source task data is available but the target sample size is small.
For such settings, we obtain a sharp transition from positive transfer to negative transfer determined by $\Delta_{\bias} - \Delta_{\vari}$.
%determined by the covariate shift matrix and the model shift.
%The bounds get tighter and tighter as $\rho_1$ increases.
While the general form of the threshold can be complex (as is preivous generalization bounds for MTL), they admit interpretable forms for simplified settings.
This will be the focus of Section \ref{sec_insight}.


\textbf{Proof Overview.} We first describe the proof of Theorem \ref{lem_cov_shift_informal}.
We use the Stieltjes transform method (or the resolvent method) in random matrix theory \cite{bai2009spectral,tao2012topics,erdos2017dynamical}. Roughly speaking, we study the resolvent $R(z):=[\Sigma_2^{-1/2}( X_1^{\top}X_1 + X_2^{\top}X_2)\Sigma_2^{-1/2}-z]^{-1}$ for $z\in \C$ around $z=0$.
Using the methods in \cite{Anisotropic,yang2019spiked}, we find the asymptotic limit, say $R_\infty(z)$, of $R(z)$ for any $z$ as $p\to \infty$ with an almost optimal convergence rate. In particular, when $z=0$, $\tr[R_\infty(0)]$ gives the right hand side of \eqref{eq_introX1X2}, which concludes Theorem \ref{lem_cov_shift_informal}. The details can be found in Appendix \ref{sec_maintools} and \ref{sec_Gauss}.

Using Theorem \ref{lem_cov_shift_informal} over \eqref{eq_te_var}, we can calculate the amount of reduced variance compared to STL.
The amount of reduced variance is given by $\Delta_{\vari}$.
For the bias term of equation \eqref{eq_te_model_shift}, we apply a Gaussian concentration bound on $X_1^{\top}X_1$, whose expectation is $n_1^2\Sigma_1$.
This results in the error term $\delta$, which scales as $(1 \pm 1/\sqrt{\rho_1})^4$.
Then, we applying a similar identity to Theorem \ref{lem_cov_shift_informal} for bounding the bias term, noting that the derivative of $R(z)$ with respect to $z$ can be approximated by $R_\infty'(z)$.
This leads to a negative effect given by $\Delta_{\bias}$. %, which will be used to estimate the first term on the right hand side of \eqref{eq_te_model_shift}.
%During this process, we will get the $\Delta_{\bias}$ term up to an error $\delta$ depending on $\rho_1$.
The details are presented in Appendix \ref{app_proof_main}.

%The proof of Theorem \ref{thm_main_informal} is presented in Appendix \ref{app_proof_main}.
Next, we describe our result for more than two tasks with same features, i.e. $X_i = X$ for any $i$.
This setting is prevalent in applications of multi-task learning to image classification, where there are multiple prediction labels/tasks for every image \cite{chexnet17,EA20}.
\begin{theorem}\label{thm_many_tasks}
%Suppose $X=Z\Sigma^{1/2}\in \R^{n\times p}$ satisfy Assumption \ref{assm_secA1} with $\rho:=n/p>1$ being some fixed constant. Consider data models  $Y_i = X\beta_i + \varepsilon_i$, $i=1,2,\cdots, t$, where $\e_i\in \R^{n}$ are random vectors with i.i.d. entries with mean zero, variance $\sigma^2$ and all moments as in \eqref{assmAhigh}. Moreover, assume that $X$, $\beta_i$ and $\e_i$ are all independent of each other.
	%Let $n = c \cdot p$.
	%Let $X\in\real^{n\times p}$ and $Y_i = X\beta_i + \varepsilon_i$, for $i = 1,\dots,k$.
	Consider $t$ data models $Y_i = X\beta_i + \varepsilon_i$, $i=1,2,\cdots, t$, that satisfy Assumption \ref{assm_secA2}.
	Let $U_r U_r^{\top}$ denote the best rank-$r$ subspace approximation of $(B^{\star})^\top\Sigma B^{\star}$, where $B^\star := [{\beta}_1,{\beta}_2,\dots,{\beta}_{t}]$ and $U_r\in\real^{t\times r}$. Suppose $(B^{\star})^\top\Sigma B^{\star}$ is of full rank in the sense that $\lambda_{\min}((B^{\star})^\top\Sigma B^{\star})\gtrsim \sigma^2$. Let $U_r(i)$ denote the $i$-th row vector of $U_r$.
	We have the following
	\squishlist
		\item We have $\te(\hat{\beta}_t^{\MTL}) < \te(\hat{\beta}_t^{\STL})$ with high probability if
		$$\left(1 - \norm{U_r(t)}^2 \right)\frac{\sigma^2}{\rho - 1} > \norm{\Sigma (B^{\star} U_r U_r(t) - \beta_t)}^2 +  \oo \left( \|B^\star\|^2 + \sigma^2\right).$$
		\item We have $\te(\hat{\beta}_t^{\MTL}) > \te(\hat{\beta}_t^{\STL})$ with high probability if
		$$\left(1 - \norm{U_r(t)}^2\right)\frac{\sigma^2}{\rho - 1} < \norm{\Sigma(B^{\star} U_r U_r(t) - \beta_t)}^2 -  \oo \left( \|B^\star\|^2 + \sigma^2\right).$$
	\squishend
\end{theorem}
%A similar result for the second setting can be found in Appendix \ref{app_proof_many_tasks}.

\textbf{Remark.} Theorem \ref{lem_cov_shift_informal} extends a well-known result for the single-task setting when $X_1, \rho_1, a_1$ are all equal to zero \cite{S07}.
The concentration error of our result that is order $O(p^{-1/2+o(1)})$ is nearly optimal.

\iffalse
\textbf{Transfer learning.}
We extend Theorem \ref{thm_main_informal} to transfer learning settings.
We study the transfer procedure used in Taskonomy by Zamir et al.'18 \cite{ZSSGM18}.
For the setting of high-dimensional linear regression, the transfer procedure is as follows.
%Specifically, the source task encoder consists of the representations learnt from one or more source tasks.
%The transfer function then tries to fit the target task data to the source task encoder.
\squishlist
	\item \textit{Learning source task representations}: we obtain $\hat{\beta}_i^{\STL}$ from each source task, for $1\le i \le t-1$.
		This forms a shared representation ${B} = [\hat{\beta}_1,\hat{\beta}_2,\dots,\hat{\beta}_{t-1}]$.
	\item \textit{Fine-tuning on the target task}: we learn the output layer $W_t\in\real^{t-1}$ similar to equation \eqref{eq_mtl}
		\begin{align}
			g(W_t) = \bignorm{X_t B W_t - Y_t}^2.
		\end{align}
\squishend
After solving $W_t$, we use $\hat{\beta}_t^{\TL} = B W_t$ as the transfer learning (TL) estimator for the target task.
Our result naturally applies to $\hat{\beta}_t^{\TL}$.
Interestingly, we show that the model shift bias is simply the projection of $\beta_t$ to the orthogonal subspace of $B^{\star} = [\beta_1,\dots,\beta_{t-1}]$, or $\norm{\Sigma_t^{1/2}(\id - B^{\star}({B^{\star}}^{\top}B^{\star})^{-1}{B^{\star}}^{\top})\beta_t}^2$ more precisely.
The formal statement is presented in Theorem \ref{prop_taskonomy} and its proof in Appendix \ref{app_proof_sec4}.
\fi


%In order to analyze the tradeoff, we develop the following technical tool, which provides a tight bound for equation \eqref{eq_te_var}.
%where $(a_1, a_2)$ is the solution to the following deterministic equations:
%	\begin{align*}
%		a_1 + a_2 = 1- \frac{1}{\rho_1 + \rho_2},\quad a_1 + \frac1{\rho_1 + \rho_2}\cdot \frac{1}{p}\sum_{i=1}^p \frac{\lambda_i^2 a_1}{\lambda_i^2 a_1 + a_2} = \frac{\rho_1}{\rho_1 + \rho_2}.
%	\end{align*}

%\textbf{Remark.} When there is only the target task, $\rho_1$ equals zero.
%Hence $a_2 = 1 - 1/ \rho_2, a_1 = 0$ and Lemma \ref{lem_cov_shift_informal} states that $\tr[(X_2^{\top}X_2)^{-1}\Sigma_2] = \sigma^2 / (\rho_2 - 1)$, which is a well-known result in random matrix theory \cite{S07}.
%Hence our result provides a necessary tool to analyze MTL in high dimensions.

