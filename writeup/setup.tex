\section{Preliminaries}
\label{sec_prelim}

We begin by defining the data model and the multi-task learning estimator that we study.
Then, we describe the bias-variance tradeoff of the MTL estimator, and show how \textit{task similarity}, \textit{sample size} and \textit{covariate shift} connect to the bias and variance of the estimator, respectively.
%Finally, we show a tight concentration bound for the bias and variance quantities using random matrix theory.

\textbf{Data models.}
Suppose we have $t$ training datasets denoted by $(X_1, Y_1), \dots, (X_t, Y_t)$.
In the high-dimensional linear regression setting (e.g. \cite{HMRT19,BLLT20}), the features of the $k$-th task $X_k\in\real^{n_i\times p}$ consists of $n_k$ feature vectors given by $x_i = \Sigma_k^{1/2}z_i$, for $1\le i \le n_k$.
Each $z_i\in\real^p$ consists of i.i.d. entries with mean zero and unit variance.
The labels $Y_k = X_k \beta_k + \varepsilon_k$, where $\varepsilon_k$ denotes i.i.d. noise with mean zero and variance $\sigma^2$.
%Recall that we have $t$ labeled training datasets, denoted by $(X_1, Y_1), (X_2, Y_2), \dots, (X_t, Y_t)$, where $X_i\in\real^{n_i\times p}$ and $Y_i\in\real^{n_i}$ for $1\le i\le t$.
%Following \cite{HMRT19,BLLT20}, we assume that for each task $i = 1,2,\dots,t$,  every feature vector is generated as $x = \Sigma_i^{1/2} z$, where $z\in\real^p$ is a random vector with i.i.d. entries of mean zero and unit variance and $\Sigma_i\in\real^{p\times p}$ is a positive semidefinite matrix.
%Without loss of generality, let the $t$-th task be the target task.

\textbf{The multi-task estimator.}
We consider the following linear multi-task learning model \cite{R17,MTDNN19,WZR20}.
\begin{align}
	\label{eq_mtl}
	f(B; W_1, \dots, W_t) = \sum_{k=1}^t \norm{X_k B W_k - Y_k}^2,
\end{align}
where $B\in\real^{p\times r}$ and $W_k\in\real^r$ for every $1\le k\le t$.
The linear layer $B$ provides a shared subspace for all tasks whereas each output layer $W_k$ fits the $k$-th task given the linear layer.
Following \cite{WZR20}, we assume that $r < t$, because otherwise minimizing $f(\cdot)$ could result in $BW_i$ being the single-task optimum.
Then applying equation \eqref{eq_mtl} will give the same estimator as single-task learning.
We define $\hat{\beta}_t^{\MTL}$ by two steps:
(i) minimizing $f(\cdot)$ over $B$;
(ii) minimize $\set{W_i}_{i=1}^k$ over an independent sample of the training set, e.g. $\OO(p^{0.99})$ suffices.
For more details, we refer the reader to Appendix \ref{app_proof_sec3}. The single-task estimator $\hat{\beta}_t^{\STL}$ is given by $(X_t^{\top}X_t)^{-1}X_t^{\top}Y_t$. 
For an estimator $\hat{\beta}\in\real^p$, we define the out-of-sample prediction loss as
	\begin{align*}
		\te_t(\hat{\beta}) = \exarg{x}{({x}^{\top}\hat{\beta} - {x}^{\top}\beta_t)^2}
		= \bignorm{\ex{\hat{\beta}} - \beta_t}^2 + \ex{\bignorm{\hat{\beta} - \ex{\hat{\beta}}}^2},
	\end{align*}
%= (\hat{\beta} - \beta_t)^{\top}\Sigma_t(\hat{\beta} - \beta_t) \\
which can be further decomposed as the bias plus the variance of $\hat{\beta}$.
%In order to relate the btradeoff to properties of the data, we need tight concentration bounds for the bias and variance.
We consider the high-dimensional regime where $n_i$ is a fixed constant $\rho_i > 1$  multiple of $p$ for every $1\le i\le t$, and $p$ is sufficiently large.
We focus on a setting where $\rho_t$ is small compared to $\set{\rho_i}_{i=1}^{t-1}$.
This setting captures the need to add more labeled data to reduce the prediction loss of the target task.
A well-known result for this setting states that $\te_t(\hat{\beta}_t^{\STL}) = \sigma^2 \cdot \tr[(X_t^{\top}X_t)^{-1}\Sigma_t]$ is concentrated around $\frac {\sigma^2} {\rho_t - 1}$ (e.g. Chapter 6 of \cite{S07}), which scales with the data size and noise level of the target task.
However, this result only applies to a single task.
Therefore, our goal is to extend this result to multiple tasks.

\textbf{Notations.}
When there is no ambiguity, we drop the subscript $t$ from $\te_t(\hat{\beta}_t^{\MTL})$ and write $\te(\hat{\beta}_t^{\MTL})$ for simplicity.
We refer to the first task as the source task when there are only two tasks.
%We call $M = \Sigma_1^{1/2}\Sigma_2^{-1/2}$ the covariate shift matrix.
We say there is negative transfer if the prediction loss of $\hat{\beta}_t^{\MTL}$ is larger than that of $\hat{\beta}_t^{\STL}$, or positive transfer otherwise.
For a matrix $X$, let $\lambda_{\min}(X)$ denote its smallest singular value and $\norm{X}$ denote its spectral norm.

%\subsection{Analyzing the Tradeoff via Random Matrix Theory}

\textbf{Bias-variance tradeoff.}
To illustrate our intuition, we begin by considering the setting of two tasks with general covariance matrices.
%Recall that $\hat{\beta}_t^{\MTL}$ is defined as $BW_t$ after solving equation \eqref{eq_mtl}.
We decompose the test error of $\hat{\beta}_{t}^{\MTL}$ on the target task into two parts as follows.
\begin{align}
	\te(\hat{\beta}_t^{\MTL}) =& ~ \hat{v}^2 \bignorm{\Sigma_2^{1/2} (\hat{v}^2 X_1^{\top}X_1 + X_2^{\top}X_2)^{-1}X_1^{\top}X_1 (\beta_1 - \hat{v}\beta_2)}^2 \label{eq_te_model_shift} \\
	&+ \sigma^2\cdot \bigtr{(\hat{v}^2 X_1^{\top}X_1 + X_2^{\top}X_2)^{-1}\Sigma_2}, \label{eq_te_var}
\end{align}
Here $\hat{v}\in\real$ denotes a fixed value that depends on the output layer weights $W_1, W_2$.
The role of $\hat{v}$ is to scale the shared subspace $B$ to fit each task.
These are derived in Appendix \ref{app_proof_sec3}.

The term on the right-hand side of \eqref{eq_te_model_shift} corresponds to the bias of $\hat{\beta}_t^{\MTL}$, which captures how similar $\beta_1$ and $\beta_2$ are.
Hence, the bias of $\hat{\beta}_t^{\MTL}$ introduces a negative effect from adding the source labels.
Equation \eqref{eq_te_var} corresponds to the variance of $\hat{\beta}_t^{\MTL}$, which is always smaller than the variance of $\hat{\beta}_t^{\STL}$.
%This part introduces a positive variance reduction effect from adding the source labels.
Hence, whether $\te(\hat{\beta}_t^{\MTL}) < \te(\hat{\beta}_t^{\STL})$ is determined precisely by the tradeoff between the negative effect of the bias term and the positive effect of the variance term!
%(i) the negative effect from model shift bias.
%(ii) the positive effect from variance reduction;



\iffalse
\textbf{Transfer learning.}
We extend Theorem \ref{thm_main_informal} to transfer learning settings.
We study the transfer procedure used in Taskonomy by Zamir et al.'18 \cite{ZSSGM18}.
For the setting of high-dimensional linear regression, the transfer procedure is as follows.
%Specifically, the source task encoder consists of the representations learnt from one or more source tasks.
%The transfer function then tries to fit the target task data to the source task encoder.
\squishlist
	\item \textit{Learning source task representations}: we obtain $\hat{\beta}_i^{\STL}$ from each source task, for $1\le i \le t-1$.
		This forms a shared representation ${B} = [\hat{\beta}_1,\hat{\beta}_2,\dots,\hat{\beta}_{t-1}]$.
	\item \textit{Fine-tuning on the target task}: we learn the output layer $W_t\in\real^{t-1}$ similar to equation \eqref{eq_mtl}
		\begin{align}
			g(W_t) = \bignorm{X_t B W_t - Y_t}^2.
		\end{align}
\squishend
After solving $W_t$, we use $\hat{\beta}_t^{\TL} = B W_t$ as the transfer learning (TL) estimator for the target task.
Our result naturally applies to $\hat{\beta}_t^{\TL}$.
Interestingly, we show that the model shift bias is simply the projection of $\beta_t$ to the orthogonal subspace of $B^{\star} = [\beta_1,\dots,\beta_{t-1}]$, or $\norm{\Sigma_t^{1/2}(\id - B^{\star}({B^{\star}}^{\top}B^{\star})^{-1}{B^{\star}}^{\top})\beta_t}^2$ more precisely.
The formal statement is presented in Theorem \ref{prop_taskonomy} and its proof in Appendix \ref{app_proof_sec4}.
\fi


%In order to analyze the tradeoff, we develop the following technical tool, which provides a tight bound for equation \eqref{eq_te_var}.
%where $(a_1, a_2)$ is the solution to the following deterministic equations:
%	\begin{align*}
%		a_1 + a_2 = 1- \frac{1}{\rho_1 + \rho_2},\quad a_1 + \frac1{\rho_1 + \rho_2}\cdot \frac{1}{p}\sum_{i=1}^p \frac{\lambda_i^2 a_1}{\lambda_i^2 a_1 + a_2} = \frac{\rho_1}{\rho_1 + \rho_2}.
%	\end{align*}

%\textbf{Remark.} When there is only the target task, $\rho_1$ equals zero.
%Hence $a_2 = 1 - 1/ \rho_2, a_1 = 0$ and Lemma \ref{lem_cov_shift_informal} states that $\tr[(X_2^{\top}X_2)^{-1}\Sigma_2] = \sigma^2 / (\rho_2 - 1)$, which is a well-known result in random matrix theory \cite{S07}.
%Hence our result provides a necessary tool to analyze MTL in high dimensions.

