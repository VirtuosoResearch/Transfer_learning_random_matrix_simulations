\section{Related Work}

\textbf{Multi-task learning.}
 Adding a regularization over $B$, e.g. \cite{LPTV09,LPVT11}.
Moreover, \cite{KD12} observed that controlling the capacity can outperform the implicit capacity control of adding regularization over $B$.


\textbf{Random matrix theory.} The random matrix theory tool and related proof of this paper fall into a paradigm of the so-called local law of random matrices \cite{erdos2017dynamical}. For a sample covariance matrix $X^\top X$ with $\Sigma=\id$, such a local law was proved in \cite{isotropic}. It was later extended to sample covariance matrices with non-identity $\Sigma$ \cite{Anisotropic}, and separable covariance matrices \cite{yang2019spiked}. On the other hand, one may derive the asymptotic result in Theorem \ref{lem_cov_shift_informal} with error $\oo(1)$ using free addition of two independent random matrices in free probability theory \cite{nica2006lectures}. To the best of my knowledge, we do not find an {\it explicit result} for the sum of two sample covariance matrices with general covariates in the literature. 


\textbf{Transfer learning.}

\section{Conclusions and Discussions}
