
\begin{abstract}
When does multi-task learning outperform single-task learning?
In this work, we address this question by studying the performance of predicting a particular task given multiple tasks.
We consider a multi-task learning architecture that uses a shared layer for all tasks and a separate output layer for each task.
First, for the setting of high-dimensional linear regression, we provide a sharp analysis of the bias-variance tradeoff of multi-task learning estimators.
We develop a technical tool on the inverse of the sum of two random matrices that naturally arises from the analysis.
We extend the result to the related setting of transfer learning.
Second, we apply our tool to rigorously explain when multi-task learning outperforms single-task learning.
%And we theoretically analyze the benefit of multi-task learning for reducing the amount of labeled data needed to achieve comparable performance to single-task learning. %, which has been a key empirical finding in recent work.
Finally, we show practical implications of our theory for detecting and mitigating negative effects in image and text classification tasks.
\end{abstract}

\section{Introduction}

%Multi-task learning is an inductive learning mechanism to improve generalization performance using related task data.
%Many state-of-the-art results in computer vision and natural language processing are obtained using multi-task learning.
Multi-task learning represents a powerful paradigm to solve complex prediction tasks in computer vision \cite{chexnet17,ZSSGM18}, natural language processing \cite{GLUE,superglue} and numerous other areas \cite{ZY17}.
%In multi-task learning, having related task data is fundamental to its performance.
%Multi-task learning is particularly powerful when there is limited labeled data for a task to be solved, meanwhile more labeled data from different but related tasks is available.
By combining multiple information sources, it is possible to share all the information in the same model.
%For example, many applications in , and many other areas have been achieved by learning from multiple tasks together.
The performance of multi-task learning depends on the relationship of the information sources \cite{C97}.
When the information sources are heterogeneous, negative transfer -- where multi-task learning performs worse than single-task learning -- has often been observed \cite{AP16,BS17}.
While numerous studies have sought to alleviate negative transfer \cite{ZY17}, a rigorous understanding of the contributing causes of negative transfer has remained elusive in the literature \cite{R17}.
%This phenomenon, known as \textit{negative transfer}, is fundamental to the understanding of multi-task learning.
In this work, we develop technical tools to compare multi-task learning to single-task learning for the setting of high-dimensional linear regression. % for learning from multiple linear regression tasks.
We use the tools to rigorously explain the phenomena of negative transfer.
Our theory also leads to practical implications: we propose a diagnostic metric and a training schedule to improve multi-task training.
%We consider a setting where the target task has limited labeled data and show
%On the other hand, unless the structures across task data are well-understood, applying multi-task learning on several different datasets often result in suboptimal models (or negative transfer in more technical terms).

Identifying negative transfer requires developing tight generalization bounds for both multi-task learning and single-task learning.
In classical Rademacher or VC based theory of multi-task learning \cite{B00,AZ05,M06}, the generalization bounds are usually presented so that the error reduces as the data sizes of all tasks increase.
For instance, the data sizes of all tasks are often assumed to be equal \cite{B00}.
On the other hand, uneven data sizes or dominating tasks have been empirically observed as a cause of negative transfer \cite{YKGLHF20}.
More recent work has shown the benefit of learning multi-task representations for certain half-spaces \cite{MPR16} and sparse regression \cite{LPTV09,LPVT11}.
To rigorously study negative transfer, the technical challenge is to develop generalization bounds that scale tightly with properties of the data.


In this work, we consider the setting of high-dimensional linear regression and focus on predicting a particular task whose amount of labeled data is limited.
Following Hastie et al. \cite{HMRT19} and Bartlett et al. \cite{BLLT20}, we assume that for every task $1\le i\le t$, its features are random vectors $x = \Sigma_i^{1/2}z$, where $z\in\real^p$ consists of i.i.d. entries with mean zero and unit variance, and $\Sigma_i\in\real^{p\times p}$ is a positive semidefinite matrix.
Let $n_i$ denote the data size and $X_i\in\real^{n_i\times p}$ denote the features of task $i$.
The labels of task $i$ are given by $Y_i = X_i\beta_i + \varepsilon_i$, where $\beta_i\in\real^p$ denotes task $i$'s ground truth parameters and $\varepsilon_i$ denotes i.i.d. random noise with mean zero and variance $\sigma^2$.
Without loss of generality, let the $t$-th task denote the target task.
Importantly, the target task's data size is a fixed constant times $p$ in the high-dimensional setting.
Hence adding more labeled data can help improve its test performance.
%We shall assume that each task data follows a linear model, i.e. $y_i = X_i \beta_i + \varepsilon_i$, $1\le i\le k$.
%Here $\beta_i\in\real^p$ is the model parameter for the $i$-th task.
%Each row of $X_i\in\real^{n_i\times p}$ is assumed to be drawn i.i.d. from a fixed
%distribution with covariance matrix $\Sigma_i$.
We focus on the hard parameter sharing architecture with a linear shared layer $B\in\real^{p\times r}$ for all tasks and a separate prediction head $\set{W_i \in \real^{r}}_{i=1}^t$ for each task \cite{R17,MTDNN19,WZR20}.
%This corresponds to minimizing $ \sum_{i=1}^t \norm{X_i B W_i - Y_i}^2$.
Let $\hat{\beta}_t^{\MTL} = B W_t$ denote the optimal multi-task (MTL) estimator for the target task.
Let $\hat{\beta}_t^{\STL}$ denote the single-task (STL) estimator.
We define these precisely in Section \ref{sec_setup}.
We say there is negative transfer if the prediction loss of $\hat{\beta}_t^{\MTL}$  is larger than that of $\hat{\beta}_t^{\STL}$, or positive transfer otherwise.

\textbf{Main results.}
We revisit the bias-variance tradeoff of the multi-task estimator.
Interestingly, we observe that the variance of the multi-task estimator is always smaller than the variance of the single-task estimator, hence resulting in a positive effect of variance reduction.
The bias of the multi-task estimator results in a negative effect caused by the difference between $\beta_t$ and the rest of $\set{\beta_i}_{i=1}^{t-1}$.
Hence, the bias-variance tradeoff determines whether we observe positive or negative transfer.

Our first contribution is to develop a new technical tool for a quantity that arises naturally from the analysis of two tasks.
Concretely, we show a tight bound on the trace of $(X_1^{\top}X_1 + X_2^{\top}X_2)^{-1}$, which extends a well-known result on the trace of $(X_1^{\top}X_1)^{-1}$ for the single-task setting \cite{S07}.
Our analysis yields nearly optimal concentration error, which may be of independent interest.
Using this tool, we show the following results in Section \ref{sec_main}.
\squishlist
	\item We provide a sharp analysis of the bias-variance tradeoff of $\hat{\beta}_t^{\MTL}$ for two settings:
(i) two tasks with general covariance matrice; (ii) any number of tasks that have the same features (e.g. images).
	\item We extend our result to transfer learning in the setting of high-dimensional linear regression.
	We pool learnt source task representations into a shared body similar to $B$ in the hard parameter sharing architecture, as in Taskonomy by Zamir et al.'18 \cite{ZSSGM18}.
	We show that the model shift bias can be captured by the projection of $\beta_t$ to the orthogonal subspace spanned by $\set{\beta_i}_{i=1}^{t-1}$.
\squishend

Our second contribution is to use our newly developed technical tool to rigorously explain negative transfer in multi-task learning.
In Section \ref{sec_insight}, we identify three factors including task similarity, data size and covariate shift.
\squishlist
		\item First, we define task dissimilarity as the distance between $\beta_1$ and $\beta_2$ using a simplified isotropic setting of two tasks.
		Using our technical tool, we show a sharp transition from positive to negative transfer as task dissimilarity increases.
		Furthermore, we show that negative transfer is more likely to occur when the source task labels are particularly noisy.
%		In Section \ref{sec_validate}, we validate the observation on text and image classification tasks.
%	In , we provide the trade-off between $\norm{\beta_1 - \beta_2}^2$ and a certain function $\Phi(\rho_1, \rho_2)$ to determine the type of transfer.
		\item Second, we consider the effect of uneven data sizes.
	We begin by observing that adding more labeled data from the source task does not always improve performance.
	Then, we theoretically analyze the benefit of multit-task learning for reducing the amount of labeled data needed to achieve comparable performance to single-task learning, which is a key empirical finding of Taskonomy \cite{ZSSGM18}.
%	We define the \textit{data efficiency ratio} as the smallest $x$ such that if we only use an $$ fraction of labeled data, then the test error of $\hat{\beta}_t^{\MTL}$ matches that of the $\hat{\beta}_t^{\STL}$ on the entire set.
	%In Proposition \ref{prop_data_efficiency}, we show that the data efficiency ratio of an illustrative example is at most $\alert{\frac {1}{2\rho_t}}$.
	%In Section \ref{sec_validate}, we validate that performing multi-task learning can reduce the need for labeled data on 6 sentiment analysis tasks. %, we observe that just by using \alert{40\%} of the labeled data, the overall accuracy of multi-task learning matches that of learning every task in isolation.
		\item Finally, we show that covariate shift, measured by $\Sigma_1^{1/2}\Sigma_2^{-1/2}$, is another cause for suboptimal performance for $\hat{\beta}_t^{\MTL}$.
		We show that as $n_1 / n_2$ becomes large, the source task should have the same covariance matrix as the target task to ensure the best performance.
%		On the other hand, when $n_1 / n_2$ is small, there are counter examples where having the same covariance matrix is not necessarily the optimal choice.
\squishend

Our final contribution is to connect our theory to practical problems of interest.
First, we provide a metric to determine positive versus negative transfer by comparing the test accuracies of single-task models.
Second, \todo{}
Finally, we provide a new insight on the covariance alignment algorithm, proposed in \cite{WZR20}.
We show that as the size of the source task becomes larger compared to the target task, the covariance alignment algorithm produces more significant results.

