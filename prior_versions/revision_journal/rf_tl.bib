@inproceedings{lei2021near,
  title={Near-Optimal Linear Regression under Distribution Shift},
  author={Lei, Qi and Hu, Wei and Lee, Jason},
  booktitle={International Conference on Machine Learning},
  pages={6164--6174},
  year={2021},
  organization={PMLR}
}


@article{kalan2020minimax,
	title={Minimax Lower Bounds for Transfer Learning with Linear and One-hidden Layer Neural Networks},
	author={Kalan, Seyed Mohammadreza Mousavi and Fabian, Zalan and Avestimehr, A Salman and Soltanolkotabi, Mahdi},
	journal={arXiv preprint arXiv:2006.10581},
	year={2020}
}

@article{cao2019learning,
	title={Learning imbalanced datasets with label-distribution-aware margin loss},
	author={Cao, Kaidi and Wei, Colin and Gaidon, Adrien and Arechiga, Nikos and Ma, Tengyu},
	journal={arXiv preprint arXiv:1906.07413},
	year={2019}
}

@article{chen2021weighted,
	title={Weighted Training for Cross-Task Learning},
	author={Chen, Shuxiao and Crammer, Koby and He, Hangfeng and Roth, Dan and Su, Weijie J},
	journal={arXiv preprint arXiv:2105.14095},
	year={2021}
}

@article{hastie2019surprises,
	title={Surprises in high-dimensional ridgeless least squares interpolation},
	author={Hastie, Trevor and Montanari, Andrea and Rosset, Saharon and Tibshirani, Ryan J},
	journal={arXiv preprint arXiv:1903.08560},
	year={2019}
}

@article{bartlett2020benign,
	title={Benign overfitting in linear regression},
	author={Bartlett, Peter L and Long, Philip M and Lugosi, G{\'a}bor and Tsigler, Alexander},
	journal={Proceedings of the National Academy of Sciences},
	volume={117},
	number={48},
	pages={30063--30070},
	year={2020},
	publisher={National Acad Sciences}
}

@article{liang2020just,
	title={Just interpolate: Kernel “ridgeless” regression can generalize},
	author={Liang, Tengyuan and Rakhlin, Alexander and others},
	journal={Annals of Statistics},
	volume={48},
	number={3},
	pages={1329--1347},
	year={2020},
	publisher={Institute of Mathematical Statistics}
}

@article{montanari2019generalization,
	title={The generalization error of max-margin linear classifiers: High-dimensional asymptotics in the overparametrized regime},
	author={Montanari, Andrea and Ruan, Feng and Sohn, Youngtak and Yan, Jun},
	journal={arXiv preprint arXiv:1911.01544},
	year={2019}
}

@article{liang2020precise,
	title={A precise high-dimensional asymptotic theory for boosting and min-l1-norm interpolated classifiers},
	author={Liang, Tengyuan and Sur, Pragya},
	journal={arXiv preprint arXiv:2002.01586},
	year={2020}
}

@article{hanneke2020value,
	title={On the value of target data in transfer learning},
	author={Hanneke, Steve and Kpotufe, Samory},
	journal={arXiv preprint arXiv:2002.04747},
	year={2020}
}

@article{hanneke2020no,
	title={A no-free-lunch theorem for multitask learning},
	author={Hanneke, Steve and Kpotufe, Samory},
	journal={arXiv preprint arXiv:2006.15785},
	year={2020}
}

@article{tian2021transfer,
	title={Transfer Learning under High-dimensional Generalized Linear Models},
	author={Tian, Ye and Feng, Yang},
	journal={arXiv preprint arXiv:2105.14328},
	year={2021}
}

@article{cai2021transfer,
	title={Transfer learning for nonparametric classification: Minimax rate and adaptive classifier},
	author={Cai, T Tony and Wei, Hongji},
	journal={The Annals of Statistics},
	volume={49},
	number={1},
	pages={100--128},
	year={2021},
	publisher={Institute of Mathematical Statistics}
}

@inproceedings{david2010impossibility,
	title={Impossibility theorems for domain adaptation},
	author={David, Shai Ben and Lu, Tyler and Luu, Teresa and P{\'a}l, D{\'a}vid},
	booktitle={Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
	pages={129--136},
	year={2010},
	organization={JMLR Workshop and Conference Proceedings}
}

@article{wu2020optimal,
	title={On the Optimal Weighted $\ell_2$ Regularization in Overparameterized Linear Regression},
	author={Wu, Denny and Xu, Ji},
	journal={Advances in Neural Information Processing Systems},
	volume={33},
	year={2020}
}

@inproceedings{richards2021asymptotics,
	title={Asymptotics of ridge (less) regression under general source condition},
	author={Richards, Dominic and Mourtada, Jaouad and Rosasco, Lorenzo},
	booktitle={International Conference on Artificial Intelligence and Statistics},
	pages={3889--3897},
	year={2021},
	organization={PMLR}
}

@book{tulino2004random,
  title={Random matrix theory and wireless communications},
  author={Tulino, Antonia M and Verd{\'u}, Sergio},
  year={2004},
  publisher={Now Publishers Inc}
}


@article{lounici2011oracle,
  title={Oracle inequalities and optimal inference under group sparsity},
  author={Lounici, Karim and Pontil, Massimiliano and Van De Geer, Sara and Tsybakov, Alexandre B},
  journal={The annals of statistics},
  volume={39},
  number={4},
  pages={2164--2204},
  year={2011},
  publisher={Institute of Mathematical Statistics}
}

@inproceedings{pontil2013excess,
  title={Excess risk bounds for multitask learning with trace norm regularization},
  author={Pontil, Massimiliano and Maurer, Andreas},
  booktitle={Conference on Learning Theory},
  pages={55--76},
  year={2013},
  organization={PMLR}
}

@article{crammer2008learning,
  title={Learning from Multiple Sources.},
  author={Crammer, Koby and Kearns, Michael and Wortman, Jennifer},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={8},
  year={2008}
}

@article{mei2019generalization,
  title={The Generalization Error of Random Features Regression: Precise Asymptotics and the Double Descent Curve},
  author={Mei, Song and Montanari, Andrea},
  journal={Communications on Pure and Applied Mathematics},
  year={2019},
  publisher={Wiley Online Library}
}

@article{belkin2019reconciling,
  title={Reconciling modern machine-learning practice and the classical bias--variance trade-off},
  author={Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
  journal={Proceedings of the National Academy of Sciences},
  volume={116},
  number={32},
  pages={15849--15854},
  year={2019},
  publisher={National Acad Sciences}
}

@book{wainwright2019high,
  title={High-dimensional statistics: A non-asymptotic viewpoint},
  author={Wainwright, Martin J},
  volume={48},
  year={2019},
  publisher={Cambridge University Press}
}

@inproceedings{koh2021wilds,
  title={Wilds: A benchmark of in-the-wild distribution shifts},
  author={Koh, Pang Wei and Sagawa, Shiori and Xie, Sang Michael and Zhang, Marvin and Balsubramani, Akshay and Hu, Weihua and Yasunaga, Michihiro and Phillips, Richard Lanas and Gao, Irena and Lee, Tony and others},
  booktitle={International Conference on Machine Learning},
  pages={5637--5664},
  year={2021},
  organization={PMLR}
}

@article{lounici2011oracle,
  title={Oracle inequalities and optimal inference under group sparsity},
  author={Lounici, Karim and Pontil, Massimiliano and Van De Geer, Sara and Tsybakov, Alexandre B},
  journal={The annals of statistics},
  volume={39},
  number={4},
  pages={2164--2204},
  year={2011},
  publisher={Institute of Mathematical Statistics}
}

@article{mousavi2020minimax,
  title={Minimax Lower Bounds for Transfer Learning with Linear and One-hidden Layer Neural Networks},
  author={Kalan, Mohammadreza Mousavi and Fabian, Zalan and Avestimehr, Salman and Soltanolkotabi, Mahdi},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{kouw2018introduction,
  title={An introduction to domain adaptation and transfer learning},
  author={Kouw, Wouter M and Loog, Marco},
  journal={arXiv preprint arXiv:1812.11806},
  year={2018}
}
